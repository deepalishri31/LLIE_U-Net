{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ruJ747JPtg9S"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "import os, time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "#Image.fromarray(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OGrd0x9IzrUu"
      },
      "outputs": [],
      "source": [
        "import scipy as scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.7.3'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scipy.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yHNoivn4Utdn"
      },
      "outputs": [],
      "source": [
        "#from scipy.stats import betabinom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oZDEq4jfUN67"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m84YRMT21zQe",
        "outputId": "78dd5381-b45e-429a-b55b-3fcd1644de82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf_slim in /Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages (from tf_slim) (0.15.0)\n",
            "Requirement already satisfied: six in /Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages (from absl-py>=0.2.2->tf_slim) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade tf_slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k5WjR8ob15ao"
      },
      "outputs": [],
      "source": [
        "import tf_slim as slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ndQG6xim11gm"
      },
      "outputs": [],
      "source": [
        "#import tensorflow.contrib.slim as slim\n",
        "import numpy as np\n",
        "#import rawpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al13Sit_2Yub",
        "outputId": "90093773-9803-492c-de7e-1900235f5699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rawpy in /Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages (0.17.2)\n",
            "Requirement already satisfied: numpy in /Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages (from rawpy) (1.22.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install rawpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2qWvHav72fOm"
      },
      "outputs": [],
      "source": [
        "import rawpy as rawpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WHf31NXF2cGl"
      },
      "outputs": [],
      "source": [
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Gp4i9QzfTV",
        "outputId": "f0ba2125-f416-4b01-ab23-b15b3bd47eb3"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive',force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "niwzhBxwtkv6"
      },
      "outputs": [],
      "source": [
        "input_dir = '/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/dataset/Fuji/Fuji/short/'\n",
        "gt_dir = '/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/dataset/Fuji/Fuji/long/'\n",
        "checkpoint_dir = '/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/'\n",
        "result_dir = '/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/result4_Fuji/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qukjP2pNzNTs"
      },
      "outputs": [],
      "source": [
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PnclahQ60b46"
      },
      "outputs": [],
      "source": [
        "# get train IDs\n",
        "train_fns = glob.glob(gt_dir + '0*.RAF')\n",
        "train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in train_fns]\n",
        "\n",
        "ps = 512  # patch size for training\n",
        "save_freq = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQYoMaJzR6Yj",
        "outputId": "47464ac2-f411-4a3c-a567-0cb8fdee5424"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LEuZFQHs0e_F"
      },
      "outputs": [],
      "source": [
        "def lrelu(x):\n",
        "    return tf.maximum(x * 0.2, x)\n",
        "\n",
        "\n",
        "def upsample_and_concat(x1, x2, output_channels, in_channels):\n",
        "    pool_size = 2\n",
        "    deconv_filter = tf.Variable(tf.random.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
        "    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
        "\n",
        "    deconv_output = tf.concat([deconv, x2], 3)\n",
        "    deconv_output.set_shape([None, None, None, output_channels * 2])\n",
        "\n",
        "    return deconv_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x5ghyGO_0khJ"
      },
      "outputs": [],
      "source": [
        "def network(input):  # Unet\n",
        "    conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
        "    conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
        "    pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
        "\n",
        "    conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
        "    conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
        "    pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
        "\n",
        "    conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
        "    conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
        "    pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
        "\n",
        "    conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
        "    conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
        "    pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
        "\n",
        "    conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
        "    conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
        "\n",
        "    up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
        "    conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
        "    conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
        "\n",
        "    up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
        "    conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
        "    conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
        "\n",
        "    up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
        "    conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
        "    conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
        "\n",
        "    up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
        "    conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
        "    conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
        "\n",
        "    conv10 = slim.conv2d(conv9, 27, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
        "    out = tf.depth_to_space(conv10, 3)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mUg6jTeg0pGj"
      },
      "outputs": [],
      "source": [
        "def pack_raw(raw):\n",
        "    # pack X-Trans image to 9 channels\n",
        "    im = raw.raw_image_visible.astype(np.float32)\n",
        "    im = np.maximum(im - 1024, 0) / (16383 - 1024)  # subtract the black level\n",
        "\n",
        "    img_shape = im.shape\n",
        "    H = (img_shape[0] // 6) * 6\n",
        "    W = (img_shape[1] // 6) * 6\n",
        "\n",
        "    out = np.zeros((H // 3, W // 3, 9))\n",
        "\n",
        "    # 0 R\n",
        "    out[0::2, 0::2, 0] = im[0:H:6, 0:W:6]\n",
        "    out[0::2, 1::2, 0] = im[0:H:6, 4:W:6]\n",
        "    out[1::2, 0::2, 0] = im[3:H:6, 1:W:6]\n",
        "    out[1::2, 1::2, 0] = im[3:H:6, 3:W:6]\n",
        "\n",
        "    # 1 G\n",
        "    out[0::2, 0::2, 1] = im[0:H:6, 2:W:6]\n",
        "    out[0::2, 1::2, 1] = im[0:H:6, 5:W:6]\n",
        "    out[1::2, 0::2, 1] = im[3:H:6, 2:W:6]\n",
        "    out[1::2, 1::2, 1] = im[3:H:6, 5:W:6]\n",
        "\n",
        "    # 1 B\n",
        "    out[0::2, 0::2, 2] = im[0:H:6, 1:W:6]\n",
        "    out[0::2, 1::2, 2] = im[0:H:6, 3:W:6]\n",
        "    out[1::2, 0::2, 2] = im[3:H:6, 0:W:6]\n",
        "    out[1::2, 1::2, 2] = im[3:H:6, 4:W:6]\n",
        "\n",
        "    # 4 R\n",
        "    out[0::2, 0::2, 3] = im[1:H:6, 2:W:6]\n",
        "    out[0::2, 1::2, 3] = im[2:H:6, 5:W:6]\n",
        "    out[1::2, 0::2, 3] = im[5:H:6, 2:W:6]\n",
        "    out[1::2, 1::2, 3] = im[4:H:6, 5:W:6]\n",
        "\n",
        "    # 5 B\n",
        "    out[0::2, 0::2, 4] = im[2:H:6, 2:W:6]\n",
        "    out[0::2, 1::2, 4] = im[1:H:6, 5:W:6]\n",
        "    out[1::2, 0::2, 4] = im[4:H:6, 2:W:6]\n",
        "    out[1::2, 1::2, 4] = im[5:H:6, 5:W:6]\n",
        "\n",
        "    out[:, :, 5] = im[1:H:3, 0:W:3]\n",
        "    out[:, :, 6] = im[1:H:3, 1:W:3]\n",
        "    out[:, :, 7] = im[2:H:3, 0:W:3]\n",
        "    out[:, :, 8] = im[2:H:3, 1:W:3]\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ0J7hti0zBR",
        "outputId": "f82f7a2a-35d1-465c-82f2-10ef3c0831fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py:243: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "WARNING:tensorflow:From /Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-09 23:57:05.583859: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ]
        }
      ],
      "source": [
        "init_op = tf.initialize_all_variables()\n",
        "sess = tf.Session()\n",
        "\n",
        "tf.disable_eager_execution()\n",
        "in_image = tf.placeholder(tf.float32, [None, None, None, 9]) #Just a placeholder for assigning the values in further code\n",
        "gt_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "# Change it to the sample expression as follows. \n",
        "#init = tf.random.truncated_normal()\n",
        "#sess.run(init_op)\n",
        "out_image = network(in_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5BW23jxw04Q8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-09 23:57:06.240437: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
          ]
        }
      ],
      "source": [
        "G_loss = tf.reduce_mean(tf.abs(out_image - gt_image)) #Computes the mean of elements across dimensions of a tensor\n",
        "\n",
        "t_vars = tf.trainable_variables() #Returns all variables created with trainable=True\n",
        "lr = tf.placeholder(tf.float32) #Place for storing learning rate\n",
        "G_opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "ckpt = tf.train.get_checkpoint_state(checkpoint_dir) #Accessing checkpoint state from the ckpt directory\n",
        "if ckpt:\n",
        "    print('loaded ' + ckpt.model_checkpoint_path)\n",
        "    saver.restore(sess, ckpt.model_checkpoint_path) #Restoring the parameters saved in the checkpoint path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "w2z0M4hh1By1"
      },
      "outputs": [],
      "source": [
        "# Raw data takes long time to load. Keep them in memory after loaded.\n",
        "gt_images = [None] * 6000\n",
        "in_images = {}\n",
        "in_images['300'] = [None] * len(train_ids)\n",
        "in_images['250'] = [None] * len(train_ids)\n",
        "in_images['100'] = [None] * len(train_ids)\n",
        "\n",
        "g_loss = np.zeros((5000, 1))\n",
        "\n",
        "allfolders = glob.glob(result_dir + '*0')\n",
        "lastepoch = 0\n",
        "for folder in allfolders:\n",
        "    lastepoch = np.maximum(lastepoch, int(folder[-4:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "StU0fNi63IdM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoNsPzx5tZfy",
        "outputId": "85dbfa44-a511-49d6-b157-b8b0e9d54781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Count: 1 Train ID: 186 Loss=0.134, Time=17.658\n",
            "0 Count: 2 Train ID: 130 Loss=0.081, Time=17.764\n",
            "0 Count: 3 Train ID: 192 Loss=0.133, Time=17.831\n",
            "0 Count: 4 Train ID: 185 Loss=0.120, Time=18.356\n",
            "0 Count: 5 Train ID: 182 Loss=0.137, Time=17.444\n",
            "0 Count: 6 Train ID: 107 Loss=0.124, Time=17.368\n",
            "0 Count: 7 Train ID: 164 Loss=0.132, Time=17.476\n",
            "0 Count: 8 Train ID: 170 Loss=0.145, Time=18.425\n",
            "0 Count: 9 Train ID: 75 Loss=0.152, Time=18.169\n",
            "0 Count: 10 Train ID: 2 Loss=0.155, Time=18.698\n",
            "0 Count: 11 Train ID: 32 Loss=0.154, Time=17.673\n",
            "0 Count: 12 Train ID: 111 Loss=0.163, Time=18.019\n",
            "0 Count: 13 Train ID: 152 Loss=0.157, Time=16.465\n",
            "0 Count: 14 Train ID: 131 Loss=0.167, Time=16.826\n",
            "0 Count: 15 Train ID: 180 Loss=0.181, Time=17.605\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.meta\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.index\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.data-00000-of-00001\n",
            "INFO:tensorflow:93500\n",
            "1 Count: 1 Train ID: 28 Loss=0.184, Time=17.532\n",
            "1 Count: 2 Train ID: 141 Loss=0.195, Time=16.860\n",
            "1 Count: 3 Train ID: 179 Loss=0.197, Time=17.912\n",
            "1 Count: 4 Train ID: 170 Loss=0.193, Time=18.436\n",
            "1 Count: 5 Train ID: 22 Loss=0.185, Time=16.897\n",
            "1 Count: 6 Train ID: 32 Loss=0.186, Time=4.131\n",
            "1 Count: 7 Train ID: 92 Loss=0.184, Time=16.882\n",
            "1 Count: 8 Train ID: 75 Loss=0.184, Time=3.561\n",
            "1 Count: 9 Train ID: 17 Loss=0.178, Time=17.852\n",
            "1 Count: 10 Train ID: 135 Loss=0.182, Time=16.086\n",
            "1 Count: 11 Train ID: 39 Loss=0.180, Time=17.609\n",
            "1 Count: 12 Train ID: 116 Loss=0.188, Time=16.595\n",
            "1 Count: 13 Train ID: 84 Loss=0.188, Time=17.359\n",
            "1 Count: 14 Train ID: 45 Loss=0.190, Time=16.792\n",
            "1 Count: 15 Train ID: 11 Loss=0.185, Time=16.519\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.meta\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.index\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.data-00000-of-00001\n",
            "INFO:tensorflow:93500\n",
            "2 Count: 1 Train ID: 73 Loss=0.184, Time=16.516\n",
            "2 Count: 2 Train ID: 60 Loss=0.182, Time=17.287\n",
            "2 Count: 3 Train ID: 171 Loss=0.189, Time=18.290\n",
            "2 Count: 4 Train ID: 36 Loss=0.184, Time=17.107\n",
            "2 Count: 5 Train ID: 26 Loss=0.185, Time=16.744\n",
            "2 Count: 6 Train ID: 35 Loss=0.185, Time=17.834\n",
            "2 Count: 7 Train ID: 139 Loss=0.184, Time=17.022\n",
            "2 Count: 8 Train ID: 104 Loss=0.184, Time=17.019\n",
            "2 Count: 9 Train ID: 80 Loss=0.181, Time=17.405\n",
            "2 Count: 10 Train ID: 183 Loss=0.182, Time=17.570\n",
            "2 Count: 11 Train ID: 10 Loss=0.180, Time=16.612\n",
            "2 Count: 12 Train ID: 137 Loss=0.182, Time=16.770\n",
            "2 Count: 13 Train ID: 142 Loss=0.184, Time=17.509\n",
            "2 Count: 14 Train ID: 61 Loss=0.182, Time=17.335\n",
            "2 Count: 15 Train ID: 102 Loss=0.182, Time=17.441\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.meta\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.index\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.data-00000-of-00001\n",
            "INFO:tensorflow:93500\n",
            "3 Count: 1 Train ID: 59 Loss=0.180, Time=17.701\n",
            "3 Count: 2 Train ID: 36 Loss=0.180, Time=18.533\n",
            "3 Count: 3 Train ID: 142 Loss=0.178, Time=16.901\n",
            "3 Count: 4 Train ID: 78 Loss=0.176, Time=16.957\n",
            "3 Count: 5 Train ID: 141 Loss=0.173, Time=4.562\n",
            "3 Count: 6 Train ID: 180 Loss=0.169, Time=17.785\n",
            "3 Count: 7 Train ID: 37 Loss=0.168, Time=17.517\n",
            "3 Count: 8 Train ID: 3 Loss=0.166, Time=17.050\n",
            "3 Count: 9 Train ID: 14 Loss=0.164, Time=17.482\n",
            "3 Count: 10 Train ID: 173 Loss=0.165, Time=18.462\n",
            "3 Count: 11 Train ID: 103 Loss=0.166, Time=17.242\n",
            "3 Count: 12 Train ID: 183 Loss=0.165, Time=17.721\n",
            "3 Count: 13 Train ID: 39 Loss=0.164, Time=4.543\n",
            "3 Count: 14 Train ID: 131 Loss=0.163, Time=4.402\n",
            "3 Count: 15 Train ID: 83 Loss=0.161, Time=18.587\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.meta\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.index\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.data-00000-of-00001\n",
            "INFO:tensorflow:93500\n",
            "4 Count: 1 Train ID: 52 Loss=0.160, Time=19.605\n",
            "4 Count: 2 Train ID: 146 Loss=0.160, Time=18.744\n",
            "4 Count: 3 Train ID: 66 Loss=0.159, Time=17.636\n",
            "4 Count: 4 Train ID: 5 Loss=0.156, Time=17.669\n",
            "4 Count: 5 Train ID: 9 Loss=0.154, Time=16.794\n",
            "4 Count: 6 Train ID: 34 Loss=0.153, Time=17.343\n",
            "4 Count: 7 Train ID: 186 Loss=0.154, Time=17.567\n",
            "4 Count: 8 Train ID: 128 Loss=0.155, Time=17.475\n",
            "4 Count: 9 Train ID: 109 Loss=0.155, Time=18.209\n",
            "4 Count: 10 Train ID: 170 Loss=0.161, Time=17.193\n",
            "4 Count: 11 Train ID: 23 Loss=0.159, Time=17.374\n",
            "4 Count: 12 Train ID: 53 Loss=0.160, Time=17.610\n",
            "4 Count: 13 Train ID: 124 Loss=0.160, Time=17.620\n",
            "4 Count: 14 Train ID: 166 Loss=0.159, Time=16.152\n",
            "4 Count: 15 Train ID: 107 Loss=0.163, Time=4.232\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.meta\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.index\n",
            "INFO:tensorflow:400\n",
            "INFO:tensorflow:/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt.data-00000-of-00001\n",
            "INFO:tensorflow:93500\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(10)\n",
        "learning_rate = 1e-4\n",
        "for epoch in range(lastepoch, 5):\n",
        "    if os.path.isdir(result_dir + '%04d' % epoch):\n",
        "        continue\n",
        "    cnt = 0\n",
        "    if epoch > 2000:\n",
        "        learning_rate = 1e-5\n",
        "\n",
        "    for ind in np.random.permutation(len(train_ids)):\n",
        "        #try: \n",
        "            # get the path from image id\n",
        "            train_id = train_ids[ind]\n",
        "            in_files = glob.glob(input_dir + '%05d_00*.RAF' % train_id)\n",
        "            in_path = in_files[np.random.random_integers(0, len(in_files) - 1)]\n",
        "            in_fn = os.path.basename(in_path)\n",
        "\n",
        "            gt_files = glob.glob(gt_dir + '%05d_00*.RAF' % train_id)\n",
        "            gt_path = gt_files[0]\n",
        "            gt_fn = os.path.basename(gt_path)\n",
        "            in_exposure = float(in_fn[9:-5])\n",
        "            gt_exposure = float(gt_fn[9:-5])\n",
        "            ratio = min(gt_exposure / in_exposure, 300)\n",
        "\n",
        "            st = time.time()\n",
        "            cnt += 1\n",
        "\n",
        "            if in_images[str(ratio)[0:3]][ind] is None:\n",
        "\n",
        "                raw = rawpy.imread(in_path)\n",
        "                in_images[str(ratio)[0:3]][ind] = np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
        "\n",
        "                gt_raw = rawpy.imread(gt_path)\n",
        "                im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
        "                gt_images[ind] = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
        "\n",
        "            # crop\n",
        "            H = in_images[str(ratio)[0:3]][ind].shape[1]\n",
        "            W = in_images[str(ratio)[0:3]][ind].shape[2]\n",
        " \n",
        "            xx = np.random.randint(0, W - ps)\n",
        "            yy = np.random.randint(0, H - ps)\n",
        "            input_patch = in_images[str(ratio)[0:3]][ind][:, yy:yy + ps, xx:xx + ps, :]\n",
        "            gt_patch = gt_images[ind][:, yy * 3:yy * 3 + ps * 3, xx * 3:xx * 3 + ps * 3, :]\n",
        "\n",
        "            if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
        "                input_patch = np.flip(input_patch, axis=1)\n",
        "                gt_patch = np.flip(gt_patch, axis=1)\n",
        "            if np.random.randint(2, size=1)[0] == 1:\n",
        "                input_patch = np.flip(input_patch, axis=2)\n",
        "                gt_patch = np.flip(gt_patch, axis=2)\n",
        "            if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
        "                input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
        "                gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\n",
        "\n",
        "            input_patch = np.minimum(input_patch, 1.0)\n",
        "\n",
        "            _, G_current, output = sess.run([G_opt, G_loss, out_image],\n",
        "                                          feed_dict={in_image: input_patch, gt_image: gt_patch, lr: learning_rate})\n",
        "            output = np.minimum(np.maximum(output, 0), 1)\n",
        "            g_loss[ind] = G_current\n",
        "\n",
        "            print('%d Count: %d Train ID: %d Loss=%.3f, Time=%.3f' % (epoch, cnt,train_id, np.mean(g_loss[np.where(g_loss)]), time.time() - st))\n",
        "\n",
        "            if epoch % save_freq == 0:\n",
        "                if not os.path.isdir(result_dir + '%04d' % epoch):\n",
        "                    os.makedirs(result_dir + '%04d' % epoch)\n",
        "\n",
        "                temp = np.concatenate((gt_patch[0, :, :, :], output[0, :, :, :]), axis=1)\n",
        "                Image.fromarray((temp*255).astype(np.uint8),mode='RGB').save(result_dir + '%04d/%05d_00_train_%d.jpg' % (epoch, train_id, ratio))\n",
        "                #scipy.misc.toimage(temp * 255, high=255, low=0, cmin=0, cmax=255).save(result_dir + '%04d/%05d_00_train_%d.jpg' % (epoch, train_id, ratio))\n",
        "            if cnt>=15:\n",
        "                break\n",
        "        #except:\n",
        "        #    print(f\"Oops! {sys.exc_info()[0]} occurred for Train ID {train_id}, moving to next training ID....\")\n",
        "    if not os.path.isdir(result_dir + 'model.ckpt'):\n",
        "        os.makedirs(result_dir + 'model.ckpt')\n",
        "    saver.save(sess, checkpoint_dir + 'model.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "67d36878585a542570ff856abf0a24408e488838428cd0e62b2d6bf0a7575ba2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
