{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UrReQaOzA-aD"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnfv0fnRBBP7",
    "outputId": "2214ae9a-7c46-4478-9dbc-141a3b9f8aaf"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bmNzQHYLBEQI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:05:45.932199: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-10 04:05:46.108020: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-10 04:05:46.108057: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-10 04:05:46.145958: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-10 04:05:46.901025: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-10 04:05:46.901113: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-10 04:05:46.901123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "#import tensorflow.contrib.slim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skfKcfvLBLj4",
    "outputId": "d5352948-6db7-480a-bcdd-fdba8680e15e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_slim in /home/21i190003/anaconda3/lib/python3.9/site-packages (1.1.0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f560b2bca00>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/tf-slim/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lKhXLtJTBMvq"
   },
   "outputs": [],
   "source": [
    "import tf_slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qX46YyH7BPc-",
    "outputId": "48316d5a-5b61-4faf-a564-c90a21d3458b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rawpy in /home/21i190003/.local/lib/python3.9/site-packages (0.17.2)\r\n",
      "Requirement already satisfied: numpy in /home/21i190003/anaconda3/lib/python3.9/site-packages (from rawpy) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rawpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fs1uYDYCBR0K"
   },
   "outputs": [],
   "source": [
    "import rawpy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "yh4jAzeSDW0y",
    "outputId": "a3ad7306-d9d3-4ec8-afae-cdaf115d2042"
   },
   "outputs": [],
   "source": [
    "# !pip install scipy==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QSJGWwNjEkmK"
   },
   "outputs": [],
   "source": [
    "import scipy as scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cF7dta6YmqeD"
   },
   "outputs": [],
   "source": [
    "input_dir = '/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/dataset/Fuji/Fuji/short/'\n",
    "gt_dir = '/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/dataset/Fuji/Fuji/long/'\n",
    "checkpoint_dir = '/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/'\n",
    "result_dir = '/Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/testresult4_dir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Wr0m2FD3mfl6"
   },
   "outputs": [],
   "source": [
    "# get test IDs\n",
    "test_fns = glob.glob(gt_dir + '1*.RAF') #For getting all the images with long exposure which start with 1 (i.e. Test images)\n",
    "test_ids = [int(os.path.basename(test_fn)[0:5]) for test_fn in test_fns] #for storing the images IDs along with the test Tag(i.e. intial integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5pcLpLCpA6VE"
   },
   "outputs": [],
   "source": [
    "def lrelu(x):\n",
    "    return tf.maximum(x * 0.2, x)\n",
    "\n",
    "\n",
    "def upsample_and_concat(x1, x2, output_channels, in_channels):\n",
    "    pool_size = 2\n",
    "    deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
    "    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
    "\n",
    "    deconv_output = tf.concat([deconv, x2], 3)\n",
    "    deconv_output.set_shape([None, None, None, output_channels * 2])\n",
    "\n",
    "    return deconv_output\n",
    "\n",
    "\n",
    "def network(input):  # Unet\n",
    "    conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
    "    conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
    "    pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
    "\n",
    "    conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
    "    conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
    "    pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
    "\n",
    "    conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
    "    conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
    "    pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
    "\n",
    "    conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
    "    conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
    "    pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
    "\n",
    "    conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
    "    conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
    "\n",
    "    up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
    "    conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
    "    conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
    "\n",
    "    up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
    "    conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
    "    conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
    "\n",
    "    up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
    "    conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
    "    conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
    "\n",
    "    up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
    "    conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
    "    conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
    "\n",
    "    conv10 = slim.conv2d(conv9, 27, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
    "    out = tf.depth_to_space(conv10, 3)\n",
    "    return out\n",
    "\n",
    "\n",
    "def pack_raw(raw):\n",
    "    # pack X-Trans image to 9 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 1024, 0) / (16383 - 1024)  # subtract the black level\n",
    "\n",
    "    img_shape = im.shape\n",
    "    H = (img_shape[0] // 6) * 6\n",
    "    W = (img_shape[1] // 6) * 6\n",
    "\n",
    "    out = np.zeros((H // 3, W // 3, 9))\n",
    "\n",
    "    # 0 R\n",
    "    out[0::2, 0::2, 0] = im[0:H:6, 0:W:6]\n",
    "    out[0::2, 1::2, 0] = im[0:H:6, 4:W:6]\n",
    "    out[1::2, 0::2, 0] = im[3:H:6, 1:W:6]\n",
    "    out[1::2, 1::2, 0] = im[3:H:6, 3:W:6]\n",
    "\n",
    "    # 1 G\n",
    "    out[0::2, 0::2, 1] = im[0:H:6, 2:W:6]\n",
    "    out[0::2, 1::2, 1] = im[0:H:6, 5:W:6]\n",
    "    out[1::2, 0::2, 1] = im[3:H:6, 2:W:6]\n",
    "    out[1::2, 1::2, 1] = im[3:H:6, 5:W:6]\n",
    "\n",
    "    # 1 B\n",
    "    out[0::2, 0::2, 2] = im[0:H:6, 1:W:6]\n",
    "    out[0::2, 1::2, 2] = im[0:H:6, 3:W:6]\n",
    "    out[1::2, 0::2, 2] = im[3:H:6, 0:W:6]\n",
    "    out[1::2, 1::2, 2] = im[3:H:6, 4:W:6]\n",
    "\n",
    "    # 4 R\n",
    "    out[0::2, 0::2, 3] = im[1:H:6, 2:W:6]\n",
    "    out[0::2, 1::2, 3] = im[2:H:6, 5:W:6]\n",
    "    out[1::2, 0::2, 3] = im[5:H:6, 2:W:6]\n",
    "    out[1::2, 1::2, 3] = im[4:H:6, 5:W:6]\n",
    "\n",
    "    # 5 B\n",
    "    out[0::2, 0::2, 4] = im[2:H:6, 2:W:6]\n",
    "    out[0::2, 1::2, 4] = im[1:H:6, 5:W:6]\n",
    "    out[1::2, 0::2, 4] = im[4:H:6, 2:W:6]\n",
    "    out[1::2, 1::2, 4] = im[5:H:6, 5:W:6]\n",
    "\n",
    "    out[:, :, 5] = im[1:H:3, 0:W:3]\n",
    "    out[:, :, 6] = im[1:H:3, 1:W:3]\n",
    "    out[:, :, 7] = im[2:H:3, 0:W:3]\n",
    "    out[:, :, 8] = im[2:H:3, 1:W:3]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xbAQc_K1zFiW"
   },
   "outputs": [],
   "source": [
    "in_files = glob.glob(input_dir + '%05d_00*.RAF' % 10110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3RfehEizJmz",
    "outputId": "b5de3e39-ef81-4d43-8541-18b80f3c9a47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "l-4RrsKuv7ak"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 04:06:47.568652: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-10 04:06:47.568706: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-10 04:06:47.568745: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kopri): /proc/driver/nvidia/version does not exist\n",
      "2022-11-10 04:06:47.569411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9e0nRCKzv_H3"
   },
   "outputs": [],
   "source": [
    "tf.disable_eager_execution()\n",
    "in_image = tf.placeholder(tf.float32, [None, None, None, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxkewdDiyyZJ",
    "outputId": "9775edec-8839-40f3-a19f-823828021fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(None, None, None, 9), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(in_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zdfWoHDewBNc"
   },
   "outputs": [],
   "source": [
    "gt_image = tf.placeholder(tf.float32, [None, None, None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXeD4lL8wDRv",
    "outputId": "f177ec68-c44c-4dff-a04a-d854506c0974"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "out_image = network(in_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc5LjaiXy8OA",
    "outputId": "2ef6a995-dd85-48ba-b812-c27b3fb2d07b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"DepthToSpace:0\", shape=(None, None, None, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "YLTagA9VzJvU"
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "7gLGmCzczcMk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 00:23:18.810286: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nnoaEnDrv4eU"
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "DeQZ5PmM6X1D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded /Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /Users/rahulvaishnav/Downloads/IITB_IEOR/Sem_3/IE643/Course_Project/Fuji_Training/ckpt4_Fuji/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "if ckpt:\n",
    "    print('loaded ' + ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tcb5iXAH6x5x"
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(result_dir + 'final/'):\n",
    "    os.makedirs(result_dir + 'final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOkE-Wuq7TZJ",
    "outputId": "48fbc366-1b5c-46e1-dced-532c1f41a1a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,2,2,2,2,3,2,2,3,2,2,2,3,2,2,2,3,2,2,2,3,3,2,3,3,2,3,3,2,2,2,2,2,2,2,3,2,2,2,3,2,"
     ]
    }
   ],
   "source": [
    "for test_id in test_ids:\n",
    "    # test the first image in each sequence\n",
    "    in_files = glob.glob(input_dir + '%05d_00*.RAF' % test_id)\n",
    "    print(len(in_files),end = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "gwsqqeXEB7SV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Test ID = 10049: \n",
      "10049_00_0.033s.RAF\n",
      "10049_00_0.1s.RAF\n",
      "for Test ID = 10055: \n",
      "10055_00_0.033s.RAF\n",
      "10055_00_0.1s.RAF\n",
      "for Test ID = 10119: \n",
      "10119_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10119, moving to next training ID....\n",
      "10119_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10119, moving to next training ID....\n",
      "for Test ID = 10090: \n",
      "10090_00_0.04s.RAF\n",
      "10090_00_0.1s.RAF\n",
      "for Test ID = 10089: \n",
      "10089_00_0.1s.RAF\n",
      "10089_00_0.04s.RAF\n",
      "for Test ID = 10155: \n",
      "10155_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10155, moving to next training ID....\n",
      "10155_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10155, moving to next training ID....\n",
      "10155_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10155, moving to next training ID....\n",
      "for Test ID = 10019: \n",
      "10019_00_0.1s.RAF\n",
      "10019_00_0.033s.RAF\n",
      "for Test ID = 10144: \n",
      "10144_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10144, moving to next training ID....\n",
      "10144_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10144, moving to next training ID....\n",
      "for Test ID = 10174: \n",
      "10174_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10174, moving to next training ID....\n",
      "10174_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10174, moving to next training ID....\n",
      "10174_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10174, moving to next training ID....\n",
      "for Test ID = 10121: \n",
      "10121_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10121, moving to next training ID....\n",
      "10121_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10121, moving to next training ID....\n",
      "for Test ID = 10029: \n",
      "10029_00_0.033s.RAF\n",
      "10029_00_0.1s.RAF\n",
      "for Test ID = 10024: \n",
      "10024_00_0.1s.RAF\n",
      "10024_00_0.033s.RAF\n",
      "for Test ID = 10165: \n",
      "10165_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10165, moving to next training ID....\n",
      "10165_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10165, moving to next training ID....\n",
      "10165_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10165, moving to next training ID....\n",
      "for Test ID = 10097: \n",
      "10097_00_0.1s.RAF\n",
      "10097_00_0.04s.RAF\n",
      "for Test ID = 10068: \n",
      "10068_00_0.1s.RAF\n",
      "10068_00_0.033s.RAF\n",
      "for Test ID = 10043: \n",
      "10043_00_0.033s.RAF\n",
      "10043_00_0.1s.RAF\n",
      "for Test ID = 10160: \n",
      "10160_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10160, moving to next training ID....\n",
      "10160_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10160, moving to next training ID....\n",
      "10160_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10160, moving to next training ID....\n",
      "for Test ID = 10113: \n",
      "10113_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10113, moving to next training ID....\n",
      "10113_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10113, moving to next training ID....\n",
      "for Test ID = 10138: \n",
      "10138_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10138, moving to next training ID....\n",
      "10138_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10138, moving to next training ID....\n",
      "for Test ID = 10040: \n",
      "10040_00_0.033s.RAF\n",
      "10040_00_0.1s.RAF\n",
      "for Test ID = 10154: \n",
      "10154_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10154, moving to next training ID....\n",
      "10154_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10154, moving to next training ID....\n",
      "10154_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10154, moving to next training ID....\n",
      "for Test ID = 10148: \n",
      "10148_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10148, moving to next training ID....\n",
      "10148_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10148, moving to next training ID....\n",
      "10148_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10148, moving to next training ID....\n",
      "for Test ID = 10094: \n",
      "10094_00_0.1s.RAF\n",
      "10094_00_0.04s.RAF\n",
      "for Test ID = 10191: \n",
      "10191_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10191, moving to next training ID....\n",
      "10191_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10191, moving to next training ID....\n",
      "10191_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10191, moving to next training ID....\n",
      "for Test ID = 10159: \n",
      "10159_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10159, moving to next training ID....\n",
      "10159_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10159, moving to next training ID....\n",
      "10159_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10159, moving to next training ID....\n",
      "for Test ID = 10099: \n",
      "10099_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10099, moving to next training ID....\n",
      "10099_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10099, moving to next training ID....\n",
      "for Test ID = 10145: \n",
      "10145_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10145, moving to next training ID....\n",
      "10145_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10145, moving to next training ID....\n",
      "10145_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10145, moving to next training ID....\n",
      "for Test ID = 10172: \n",
      "10172_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10172, moving to next training ID....\n",
      "10172_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10172, moving to next training ID....\n",
      "10172_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10172, moving to next training ID....\n",
      "for Test ID = 10051: \n",
      "10051_00_0.1s.RAF\n",
      "10051_00_0.033s.RAF\n",
      "for Test ID = 10110: \n",
      "10110_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10110, moving to next training ID....\n",
      "10110_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10110, moving to next training ID....\n",
      "for Test ID = 10063: \n",
      "10063_00_0.033s.RAF\n",
      "10063_00_0.1s.RAF\n",
      "for Test ID = 10133: \n",
      "10133_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10133, moving to next training ID....\n",
      "10133_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10133, moving to next training ID....\n",
      "for Test ID = 10027: \n",
      "10027_00_0.1s.RAF\n",
      "10027_00_0.033s.RAF\n",
      "for Test ID = 10020: \n",
      "10020_00_0.033s.RAF\n",
      "10020_00_0.1s.RAF\n",
      "for Test ID = 10134: \n",
      "10134_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10134, moving to next training ID....\n",
      "10134_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10134, moving to next training ID....\n",
      "for Test ID = 10161: \n",
      "10161_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10161, moving to next training ID....\n",
      "10161_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10161, moving to next training ID....\n",
      "10161_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10161, moving to next training ID....\n",
      "for Test ID = 10064: \n",
      "10064_00_0.033s.RAF\n",
      "10064_00_0.1s.RAF\n",
      "for Test ID = 10125: \n",
      "10125_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10125, moving to next training ID....\n",
      "10125_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10125, moving to next training ID....\n",
      "for Test ID = 10117: \n",
      "10117_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10117, moving to next training ID....\n",
      "10117_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10117, moving to next training ID....\n",
      "for Test ID = 10153: \n",
      "10153_00_0.033s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10153, moving to next training ID....\n",
      "10153_00_0.1s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10153, moving to next training ID....\n",
      "10153_00_0.04s.RAF\n",
      "Oops! <class 'rawpy._rawpy.LibRawFileUnsupportedError'> occurred for Train ID 10153, moving to next training ID....\n",
      "for Test ID = 10047: \n",
      "10047_00_0.1s.RAF\n",
      "10047_00_0.033s.RAF\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for test_id in test_ids:\n",
    "    # test the first image in each sequence\n",
    "    in_files = glob.glob(input_dir + '%05d_00*.RAF' % test_id)\n",
    "    print(f'for Test ID = {test_id}: ')\n",
    "    for k in range(len(in_files)): \n",
    "        try: \n",
    "            in_path = in_files[k] #For first image in kth sequence\n",
    "            in_fn = os.path.basename(in_path)\n",
    "            print(in_fn) #Printing the image name for first image in kth sequence\n",
    "            gt_files = glob.glob(gt_dir + '%05d_00*.RAF' % test_id) #Accessing corresponding long exposure images\n",
    "            gt_path = gt_files[0] #For taking path as string\n",
    "            gt_fn = os.path.basename(gt_path) # long exposure Image file name\n",
    "            in_exposure = float(in_fn[9:-5])\n",
    "            gt_exposure = float(gt_fn[9:-5])\n",
    "            ratio = min(gt_exposure / in_exposure, 300)\n",
    "\n",
    "            raw = rawpy.imread(in_path) #Reading the first short exposure image\n",
    "            input_full = np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
    "            im = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            # scale_full = np.expand_dims(np.float32(im/65535.0),axis = 0)*ratio #scale the low-light image using the same ratio\n",
    "            scale_full = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "\n",
    "            gt_raw = rawpy.imread(gt_path)\n",
    "            im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            gt_full = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "\n",
    "            input_full = np.minimum(input_full, 1.0)\n",
    "\n",
    "            output = sess.run(out_image, feed_dict={in_image: input_full})\n",
    "            output = np.minimum(np.maximum(output, 0), 1)\n",
    "\n",
    "            _, H, W, _ = output.shape\n",
    "\n",
    "            output = output[0, :, :, :]\n",
    "            gt_full = gt_full[0, 0:H, 0:W, :]\n",
    "            scale_full = scale_full[0, 0:H, 0:W, :]\n",
    "            scale_full = scale_full * np.mean(gt_full) / np.mean(\n",
    "                scale_full)  # scale the low-light image to the same mean of the groundtruth\n",
    "\n",
    "            Image.fromarray((output*255).astype(np.uint8),mode='RGB').save(\n",
    "                result_dir + 'final/%5d_00_%d_out.png' % (test_id, ratio))\n",
    "            Image.fromarray((scale_full*255).astype(np.uint8),mode='RGB').save(\n",
    "                result_dir + 'final/%5d_00_%d_scale.png' % (test_id, ratio))\n",
    "            Image.fromarray((gt_full*255).astype(np.uint8),mode='RGB').save(\n",
    "                result_dir + 'final/%5d_00_%d_gt.png' % (test_id, ratio))\n",
    "            #break\n",
    "        except:\n",
    "            print(f\"Oops! {sys.exc_info()[0]} occurred for Test ID {test_id}, moving to next testing ID....\")\n",
    "    k+=1\n",
    "    if k>=15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEgI0SKdQFBG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "67d36878585a542570ff856abf0a24408e488838428cd0e62b2d6bf0a7575ba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
