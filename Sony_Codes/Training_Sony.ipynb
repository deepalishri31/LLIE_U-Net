{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a7b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Training_Sony.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1GEBhrMgdTE81EYLi2hUD6Xrie9iRhLZg\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "import os, time\n",
    "\n",
    "#pip install scipy==1.2.0\n",
    "\n",
    "import scipy as scipy\n",
    "\n",
    "# uniform content loss + adaptive threshold + per_class_input + recursive G\n",
    "# improvement upon cqf37\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive',force_remount = True)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "#import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "\n",
    "#!pip install --upgrade tf_slim\n",
    "\n",
    "import tf_slim as slim\n",
    "\n",
    "import sys\n",
    "\n",
    "#pip install rawpy\n",
    "\n",
    "import rawpy as rawpy\n",
    "import glob\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f3b63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "No. of Training Images: 0\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/home/21i190003/DL_Project/Sony_Dataset/Sony/short/'\n",
    "gt_dir = '/home/21i190003/DL_Project/Sony_Dataset/Sony/long/'\n",
    "checkpoint_dir = '/home/21i190003/DL_Project/Sony_ckpt1/'\n",
    "result_dir = '/home/21i190003/DL_Project/Sony_result1/'\n",
    "print('------------------------------------------------------------------\\n------------------------------------------------------------------\\n------------------------------------------------------------------')        \n",
    "\n",
    "# get train IDs\n",
    "train_fns = glob.glob(gt_dir + '0*.ARW')\n",
    "train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in train_fns]\n",
    "\n",
    "print(f'No. of Training Images: {len(train_ids)}') #Number of reference images for training for Sony Sensor\n",
    "\n",
    "ps = 512  # patch size for training\n",
    "save_freq = 5\n",
    "\n",
    "DEBUG = 0\n",
    "if DEBUG == 1:\n",
    "    save_freq = 1\n",
    "    train_ids = train_ids[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8256516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x):\n",
    "    return tf.maximum(x * 0.2, x)\n",
    "\n",
    "def upsample_and_concat(x1, x2, output_channels, in_channels):\n",
    "    pool_size = 2\n",
    "    deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
    "    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
    "\n",
    "    deconv_output = tf.concat([deconv, x2], 3)\n",
    "    deconv_output.set_shape([None, None, None, output_channels * 2])\n",
    "\n",
    "    return deconv_output\n",
    "\n",
    "\n",
    "def network(input):\n",
    "    conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
    "    conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
    "    pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
    "\n",
    "    conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
    "    conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
    "    pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
    "\n",
    "    conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
    "    conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
    "    pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
    "\n",
    "    conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
    "    conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
    "    pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
    "\n",
    "    conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
    "    conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
    "\n",
    "    up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
    "    conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
    "    conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
    "\n",
    "    up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
    "    conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
    "    conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
    "\n",
    "    up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
    "    conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
    "    conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
    "\n",
    "    up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
    "    conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
    "    conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
    "\n",
    "    conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
    "    out = tf.depth_to_space(conv10, 2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9357db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Session....\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable g_conv1_1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/variables.py\", line 244, in variable\n    return getter(\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n    return func(*args, **current_args)\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/variables.py\", line 314, in model_variable\n    var = variable(\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n    return func(*args, **current_args)\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/layers/layers.py\", line 1771, in _model_variable_getter\n    return variables.model_variable(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m gt_image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mplaceholder(tf\u001b[39m.\u001b[39mfloat32, [\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39m3\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tf\u001b[39m.\u001b[39mdisable_v2_behavior()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m out_image \u001b[39m=\u001b[39m network(in_image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m G_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mabs(out_image \u001b[39m-\u001b[39m gt_image))\n\u001b[1;32m     <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m t_vars \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtrainable_variables()\n",
      "\u001b[1;32m/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb Cell 4\u001b[0m in \u001b[0;36mnetwork\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnetwork\u001b[39m(\u001b[39minput\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     conv1 \u001b[39m=\u001b[39m slim\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, \u001b[39m32\u001b[39;49m, [\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m], rate\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, activation_fn\u001b[39m=\u001b[39;49mlrelu, scope\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mg_conv1_1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     conv1 \u001b[39m=\u001b[39m slim\u001b[39m.\u001b[39mconv2d(conv1, \u001b[39m32\u001b[39m, [\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m], rate\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation_fn\u001b[39m=\u001b[39mlrelu, scope\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mg_conv1_2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/private/var/folders/h7/6lgdg2sd0h571fcnk8gz8x600000gn/T/ch.sudo.cyberduck/a5740d6e-f58f-4b52-9af7-e5a73ce4743b/home/21i190003/DL_Project/Sony_Codes/Training_Sony.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     pool1 \u001b[39m=\u001b[39m slim\u001b[39m.\u001b[39mmax_pool2d(conv1, [\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m], padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   current_args \u001b[39m=\u001b[39m current_scope[key_func]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    183\u001b[0m   current_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcurrent_args)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/layers/layers.py:1171\u001b[0m, in \u001b[0;36mconvolution2d\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39m@add_arg_scope\u001b[39m\n\u001b[1;32m   1152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvolution2d\u001b[39m(inputs,\n\u001b[1;32m   1153\u001b[0m                   num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                   trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1170\u001b[0m                   scope\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1171\u001b[0m   \u001b[39mreturn\u001b[39;00m convolution(\n\u001b[1;32m   1172\u001b[0m       inputs,\n\u001b[1;32m   1173\u001b[0m       num_outputs,\n\u001b[1;32m   1174\u001b[0m       kernel_size,\n\u001b[1;32m   1175\u001b[0m       stride,\n\u001b[1;32m   1176\u001b[0m       padding,\n\u001b[1;32m   1177\u001b[0m       data_format,\n\u001b[1;32m   1178\u001b[0m       rate,\n\u001b[1;32m   1179\u001b[0m       activation_fn,\n\u001b[1;32m   1180\u001b[0m       normalizer_fn,\n\u001b[1;32m   1181\u001b[0m       normalizer_params,\n\u001b[1;32m   1182\u001b[0m       weights_initializer,\n\u001b[1;32m   1183\u001b[0m       weights_regularizer,\n\u001b[1;32m   1184\u001b[0m       biases_initializer,\n\u001b[1;32m   1185\u001b[0m       biases_regularizer,\n\u001b[1;32m   1186\u001b[0m       reuse,\n\u001b[1;32m   1187\u001b[0m       variables_collections,\n\u001b[1;32m   1188\u001b[0m       outputs_collections,\n\u001b[1;32m   1189\u001b[0m       trainable,\n\u001b[1;32m   1190\u001b[0m       scope,\n\u001b[1;32m   1191\u001b[0m       conv_dims\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   current_args \u001b[39m=\u001b[39m current_scope[key_func]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    183\u001b[0m   current_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcurrent_args)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/layers/layers.py:1089\u001b[0m, in \u001b[0;36mconvolution\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope, conv_dims)\u001b[0m\n\u001b[1;32m   1068\u001b[0m df \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1069\u001b[0m       \u001b[39mif\u001b[39;00m data_format \u001b[39mand\u001b[39;00m data_format\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mNC\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mchannels_last\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1070\u001b[0m layer \u001b[39m=\u001b[39m layer_class(\n\u001b[1;32m   1071\u001b[0m     filters\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1072\u001b[0m     kernel_size\u001b[39m=\u001b[39mkernel_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     _scope\u001b[39m=\u001b[39msc,\n\u001b[1;32m   1088\u001b[0m     _reuse\u001b[39m=\u001b[39mreuse)\n\u001b[0;32m-> 1089\u001b[0m outputs \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mapply(inputs)\n\u001b[1;32m   1091\u001b[0m \u001b[39m# Add variables to collections.\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m _add_variable_to_collections(layer\u001b[39m.\u001b[39mkernel, variables_collections, \u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697\u001b[0m, in \u001b[0;36mLayer.apply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[39m\"\"\"Deprecated, do NOT use!\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \n\u001b[1;32m   1684\u001b[0m \u001b[39mThis is an alias of `self.__call__`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[39m  Output tensor(s).\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`layer.apply` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1695\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1696\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `layer.__call__` method instead.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1697\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py:568\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mscope\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scope\n\u001b[1;32m    567\u001b[0m   \u001b[39m# Actually call layer\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Layer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    571\u001b[0m   \u001b[39m# Update global default collections.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m   _add_elements_to_collection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdates, ops\u001b[39m.\u001b[39mGraphKeys\u001b[39m.\u001b[39mUPDATE_OPS)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:764\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m graph \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mget_graph()\n\u001b[1;32m    761\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mas_default(), backend\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_scope()):  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    762\u001b[0m   \u001b[39m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    763\u001b[0m   \u001b[39m# overridden).\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_build(inputs)\n\u001b[1;32m    765\u001b[0m   cast_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m    767\u001b[0m   \u001b[39m# Wrapping `call` function in autograph to allow for dynamic control\u001b[39;00m\n\u001b[1;32m    768\u001b[0m   \u001b[39m# flow and control dependencies in call. We are limiting this to\u001b[39;00m\n\u001b[1;32m    769\u001b[0m   \u001b[39m# subclassed layers as autograph is strictly needed only for\u001b[39;00m\n\u001b[1;32m    770\u001b[0m   \u001b[39m# subclassed layers and models.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m   \u001b[39m# tf_convert will respect the value of autograph setting in the\u001b[39;00m\n\u001b[1;32m    772\u001b[0m   \u001b[39m# enclosing tf.function, if any.\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:2086\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild, \u001b[39m'\u001b[39m\u001b[39m_is_default\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   2082\u001b[0m   \u001b[39m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[1;32m   2083\u001b[0m   \u001b[39m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[1;32m   2084\u001b[0m   \u001b[39m# operations.\u001b[39;00m\n\u001b[1;32m   2085\u001b[0m   \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mmaybe_init_scope(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 2086\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild(input_shapes)\n\u001b[1;32m   2087\u001b[0m \u001b[39m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[1;32m   2088\u001b[0m \u001b[39m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[1;32m   2089\u001b[0m \u001b[39m# `super.build()`\u001b[39;00m\n\u001b[1;32m   2090\u001b[0m Layer\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m, input_shapes)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/layers/convolutional.py:201\u001b[0m, in \u001b[0;36mConv.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    193\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mThe number of input channels must be evenly divisible by the number \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    195\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mof groups. Received groups=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, but the input has \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m channels \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    196\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m(full input shape is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups, input_channel,\n\u001b[1;32m    197\u001b[0m                                          input_shape))\n\u001b[1;32m    198\u001b[0m kernel_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size \u001b[39m+\u001b[39m (input_channel \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    199\u001b[0m                                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters)\n\u001b[0;32m--> 201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_weight(\n\u001b[1;32m    202\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    203\u001b[0m     shape\u001b[39m=\u001b[39;49mkernel_shape,\n\u001b[1;32m    204\u001b[0m     initializer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_initializer,\n\u001b[1;32m    205\u001b[0m     regularizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_regularizer,\n\u001b[1;32m    206\u001b[0m     constraint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_constraint,\n\u001b[1;32m    207\u001b[0m     trainable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    208\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    210\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[1;32m    211\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    212\u001b[0m       shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m       trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    217\u001b[0m       dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py:455\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m initializer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m   initializer \u001b[39m=\u001b[39m scope\u001b[39m.\u001b[39minitializer\n\u001b[0;32m--> 455\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Layer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49madd_weight(\n\u001b[1;32m    456\u001b[0m     name,\n\u001b[1;32m    457\u001b[0m     shape,\n\u001b[1;32m    458\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mas_dtype(dtype),\n\u001b[1;32m    459\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    460\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable \u001b[39mand\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable,\n\u001b[1;32m    461\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    462\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    463\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    464\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    465\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m    466\u001b[0m     getter\u001b[39m=\u001b[39;49mvs\u001b[39m.\u001b[39;49mget_variable,\n\u001b[1;32m    467\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m regularizer:\n\u001b[1;32m    470\u001b[0m   \u001b[39mif\u001b[39;00m (ops\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions()\n\u001b[1;32m    471\u001b[0m       \u001b[39mor\u001b[39;00m _should_add_regularizer(variable, existing_variables)):\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:442\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m     tf_logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    438\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`caching_device` does not work with mixed precision API. Ignoring \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[39m'\u001b[39m\u001b[39muser specified `caching_device`.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    440\u001b[0m     caching_device \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_variable_with_custom_getter(\n\u001b[1;32m    443\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    444\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    445\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[1;32m    446\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;49;00m\n\u001b[1;32m    447\u001b[0m     getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[1;32m    448\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[1;32m    449\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    450\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    451\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    452\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    453\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    454\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    455\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    456\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections_arg,\n\u001b[1;32m    457\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    458\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[1;32m    459\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m   \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    462\u001b[0m   \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    463\u001b[0m   \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m   name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[:variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:873\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    863\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    864\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    865\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> 873\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[1;32m    874\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    875\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    876\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    877\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    878\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_for_getter)\n\u001b[1;32m    880\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    882\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    883\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/ops/variable_scope.py:1616\u001b[0m, in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mget_variable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_variable\u001b[39m(name,\n\u001b[1;32m   1602\u001b[0m                  shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1614\u001b[0m                  synchronization\u001b[39m=\u001b[39mVariableSynchronization\u001b[39m.\u001b[39mAUTO,\n\u001b[1;32m   1615\u001b[0m                  aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE):\n\u001b[0;32m-> 1616\u001b[0m   \u001b[39mreturn\u001b[39;00m get_variable_scope()\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   1617\u001b[0m       _get_default_variable_store(),\n\u001b[1;32m   1618\u001b[0m       name,\n\u001b[1;32m   1619\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1620\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1621\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1622\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1623\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1624\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1625\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1626\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1627\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   1628\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1629\u001b[0m       custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   1630\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1631\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1632\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/ops/variable_scope.py:1326\u001b[0m, in \u001b[0;36mVariableScope.get_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1325\u001b[0m   dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype\n\u001b[0;32m-> 1326\u001b[0m \u001b[39mreturn\u001b[39;00m var_store\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   1327\u001b[0m     full_name,\n\u001b[1;32m   1328\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1329\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1330\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1331\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1332\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m   1333\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1334\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1335\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1336\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1337\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   1338\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1339\u001b[0m     custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   1340\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1341\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1342\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/ops/variable_scope.py:580\u001b[0m, in \u001b[0;36m_VariableStore.get_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[39mif\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mconstraint\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m function_utils\u001b[39m.\u001b[39mfn_args(custom_getter) \u001b[39mor\u001b[39;00m\n\u001b[1;32m    578\u001b[0m       function_utils\u001b[39m.\u001b[39mhas_kwargs(custom_getter)):\n\u001b[1;32m    579\u001b[0m     custom_getter_kwargs[\u001b[39m\"\u001b[39m\u001b[39mconstraint\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m constraint\n\u001b[0;32m--> 580\u001b[0m   \u001b[39mreturn\u001b[39;00m custom_getter(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcustom_getter_kwargs)\n\u001b[1;32m    581\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m   \u001b[39mreturn\u001b[39;00m _true_getter(\n\u001b[1;32m    583\u001b[0m       name,\n\u001b[1;32m    584\u001b[0m       shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m       synchronization\u001b[39m=\u001b[39msynchronization,\n\u001b[1;32m    597\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/layers/layers.py:1793\u001b[0m, in \u001b[0;36m_build_variable_getter.<locals>.layer_variable_getter\u001b[0;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlayer_variable_getter\u001b[39m(getter, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1792\u001b[0m   kwargs[\u001b[39m'\u001b[39m\u001b[39mrename\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m rename\n\u001b[0;32m-> 1793\u001b[0m   \u001b[39mreturn\u001b[39;00m _model_variable_getter(getter, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/layers/layers.py:1771\u001b[0m, in \u001b[0;36m_model_variable_getter\u001b[0;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, synchronization, aggregation, **_)\u001b[0m\n\u001b[1;32m   1769\u001b[0m   name_components[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m rename[short_name]\n\u001b[1;32m   1770\u001b[0m   name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(name_components)\n\u001b[0;32m-> 1771\u001b[0m \u001b[39mreturn\u001b[39;00m variables\u001b[39m.\u001b[39;49mmodel_variable(\n\u001b[1;32m   1772\u001b[0m     name,\n\u001b[1;32m   1773\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1774\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1775\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1776\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1777\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1778\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1779\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1780\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1781\u001b[0m     custom_getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[1;32m   1782\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1783\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1784\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   current_args \u001b[39m=\u001b[39m current_scope[key_func]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    183\u001b[0m   current_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcurrent_args)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/variables.py:314\u001b[0m, in \u001b[0;36mmodel_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    312\u001b[0m collections \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(collections \u001b[39mor\u001b[39;00m [])\n\u001b[1;32m    313\u001b[0m collections \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [ops\u001b[39m.\u001b[39mGraphKeys\u001b[39m.\u001b[39mGLOBAL_VARIABLES, ops\u001b[39m.\u001b[39mGraphKeys\u001b[39m.\u001b[39mMODEL_VARIABLES]\n\u001b[0;32m--> 314\u001b[0m var \u001b[39m=\u001b[39m variable(\n\u001b[1;32m    315\u001b[0m     name,\n\u001b[1;32m    316\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    317\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    318\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    319\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    320\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    321\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    322\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    323\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    324\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    325\u001b[0m     custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m    326\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    327\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    328\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n\u001b[1;32m    329\u001b[0m \u001b[39mreturn\u001b[39;00m var\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   current_args \u001b[39m=\u001b[39m current_scope[key_func]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    183\u001b[0m   current_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcurrent_args)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/variables.py:244\u001b[0m, in \u001b[0;36mvariable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    241\u001b[0m   getter \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    242\u001b[0m       custom_getter, reuse\u001b[39m=\u001b[39mvariable_scope\u001b[39m.\u001b[39mget_variable_scope()\u001b[39m.\u001b[39mreuse)\n\u001b[1;32m    243\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(device \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 244\u001b[0m   \u001b[39mreturn\u001b[39;00m getter(\n\u001b[1;32m    245\u001b[0m       name,\n\u001b[1;32m    246\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    247\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    248\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    249\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    250\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    251\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    252\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    253\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    254\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    255\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    256\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/ops/variable_scope.py:535\u001b[0m, in \u001b[0;36m_VariableStore.get_variable.<locals>._true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vars:\n\u001b[1;32m    530\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    531\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mNo partitioner was provided, but a partitioned version of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mvariable was found: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0. Perhaps a variable of the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mname was already created with partitioning?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[0;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_variable(\n\u001b[1;32m    536\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    537\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    538\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    539\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    540\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    541\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    542\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    543\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    544\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    545\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    546\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    547\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    548\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    549\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/ops/variable_scope.py:898\u001b[0m, in \u001b[0;36m_VariableStore._get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    893\u001b[0m   \u001b[39m# Throw away internal tf entries and only take a few lines. In some\u001b[39;00m\n\u001b[1;32m    894\u001b[0m   \u001b[39m# cases the traceback can be longer (e.g. if someone uses factory\u001b[39;00m\n\u001b[1;32m    895\u001b[0m   \u001b[39m# functions to create variables) so we take more than needed in the\u001b[39;00m\n\u001b[1;32m    896\u001b[0m   \u001b[39m# default case.\u001b[39;00m\n\u001b[1;32m    897\u001b[0m   tb \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tb \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtensorflow/python\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m x[\u001b[39m0\u001b[39m]][:\u001b[39m5\u001b[39m]\n\u001b[0;32m--> 898\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m Originally defined at:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    899\u001b[0m                    (err_msg, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(traceback\u001b[39m.\u001b[39mformat_list(tb))))\n\u001b[1;32m    900\u001b[0m found_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vars[name]\n\u001b[1;32m    901\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shape\u001b[39m.\u001b[39mis_compatible_with(found_var\u001b[39m.\u001b[39mget_shape()):\n",
      "\u001b[0;31mValueError\u001b[0m: Variable g_conv1_1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/variables.py\", line 244, in variable\n    return getter(\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n    return func(*args, **current_args)\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/variables.py\", line 314, in model_variable\n    var = variable(\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n    return func(*args, **current_args)\n  File \"/Applications/Anaconda/anaconda3/envs/tf/lib/python3.10/site-packages/tf_slim/layers/layers.py\", line 1771, in _model_variable_getter\n    return variables.model_variable(\n"
     ]
    }
   ],
   "source": [
    "print('Initiating Session....')\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "tf.disable_eager_execution()\n",
    "in_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
    "gt_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
    "tf.disable_v2_behavior()\n",
    "out_image = network(in_image)\n",
    "\n",
    "G_loss = tf.reduce_mean(tf.abs(out_image - gt_image))\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "lr = tf.placeholder(tf.float32)\n",
    "G_opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt:\n",
    "    print('loaded ' + ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "\n",
    "# Raw data takes long time to load. Keep them in memory after loaded.\n",
    "gt_images = [None] * 6000\n",
    "input_images = {}\n",
    "input_images['300'] = [None] * len(train_ids)\n",
    "input_images['250'] = [None] * len(train_ids)\n",
    "input_images['100'] = [None] * len(train_ids)\n",
    "\n",
    "g_loss = np.zeros((5000, 1))\n",
    "\n",
    "allfolders = glob.glob(result_dir + '*0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d94cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "512 , Count:  1 , Train ID: 42 , Loss=0.016 , Time=3.607\n",
      "512 , Count:  2 , Train ID: 24 , Loss=0.021 , Time=2.973\n",
      "512 , Count:  3 , Train ID: 150 , Loss=0.025 , Time=2.960\n",
      "512 , Count:  4 , Train ID: 44 , Loss=0.024 , Time=2.962\n",
      "512 , Count:  5 , Train ID: 196 , Loss=0.024 , Time=2.964\n",
      "512 , Count:  6 , Train ID: 97 , Loss=0.024 , Time=2.946\n",
      "512 , Count:  7 , Train ID: 118 , Loss=0.026 , Time=2.902\n",
      "512 , Count:  8 , Train ID: 85 , Loss=0.030 , Time=2.884\n",
      "512 , Count:  9 , Train ID: 17 , Loss=0.028 , Time=2.971\n",
      "512 , Count:  10 , Train ID: 181 , Loss=0.031 , Time=2.859\n",
      "512 , Count:  11 , Train ID: 38 , Loss=0.031 , Time=2.919\n",
      "512 , Count:  12 , Train ID: 138 , Loss=0.032 , Time=2.897\n",
      "512 , Count:  13 , Train ID: 15 , Loss=0.031 , Time=2.953\n",
      "512 , Count:  14 , Train ID: 123 , Loss=0.031 , Time=2.909\n",
      "512 , Count:  15 , Train ID: 214 , Loss=0.032 , Time=2.982\n",
      "512 , Count:  16 , Train ID: 175 , Loss=0.031 , Time=2.871\n",
      "512 , Count:  17 , Train ID: 81 , Loss=0.030 , Time=2.926\n",
      "512 , Count:  18 , Train ID: 62 , Loss=0.030 , Time=2.940\n",
      "512 , Count:  19 , Train ID: 180 , Loss=0.029 , Time=2.916\n",
      "512 , Count:  20 , Train ID: 67 , Loss=0.028 , Time=2.865\n",
      "512 , Count:  21 , Train ID: 23 , Loss=0.028 , Time=2.918\n",
      "512 , Count:  22 , Train ID: 59 , Loss=0.027 , Time=2.902\n",
      "512 , Count:  23 , Train ID: 50 , Loss=0.026 , Time=2.940\n",
      "512 , Count:  24 , Train ID: 232 , Loss=0.027 , Time=2.924\n",
      "512 , Count:  25 , Train ID: 109 , Loss=0.026 , Time=2.961\n",
      "512 , Count:  26 , Train ID: 121 , Loss=0.026 , Time=2.903\n",
      "512 , Count:  27 , Train ID: 31 , Loss=0.026 , Time=2.877\n",
      "512 , Count:  28 , Train ID: 27 , Loss=0.026 , Time=2.856\n",
      "512 , Count:  29 , Train ID: 173 , Loss=0.026 , Time=2.917\n",
      "512 , Count:  30 , Train ID: 84 , Loss=0.026 , Time=2.856\n",
      "512 , Count:  31 , Train ID: 171 , Loss=0.026 , Time=2.908\n",
      "512 , Count:  32 , Train ID: 36 , Loss=0.026 , Time=2.915\n",
      "512 , Count:  33 , Train ID: 49 , Loss=0.026 , Time=2.856\n",
      "512 , Count:  34 , Train ID: 134 , Loss=0.026 , Time=2.893\n",
      "512 , Count:  35 , Train ID: 94 , Loss=0.026 , Time=2.892\n",
      "512 , Count:  36 , Train ID: 231 , Loss=0.027 , Time=2.863\n",
      "512 , Count:  37 , Train ID: 136 , Loss=0.026 , Time=2.896\n",
      "512 , Count:  38 , Train ID: 48 , Loss=0.026 , Time=2.844\n",
      "512 , Count:  39 , Train ID: 216 , Loss=0.027 , Time=2.936\n",
      "512 , Count:  40 , Train ID: 72 , Loss=0.027 , Time=2.868\n",
      "512 , Count:  41 , Train ID: 141 , Loss=0.027 , Time=2.860\n",
      "512 , Count:  42 , Train ID: 135 , Loss=0.026 , Time=2.858\n",
      "512 , Count:  43 , Train ID: 63 , Loss=0.026 , Time=2.894\n",
      "512 , Count:  44 , Train ID: 164 , Loss=0.026 , Time=2.907\n",
      "512 , Count:  45 , Train ID: 205 , Loss=0.027 , Time=2.903\n",
      "512 , Count:  46 , Train ID: 71 , Loss=0.026 , Time=2.906\n",
      "512 , Count:  47 , Train ID: 206 , Loss=0.027 , Time=2.932\n",
      "512 , Count:  48 , Train ID: 43 , Loss=0.027 , Time=2.835\n",
      "512 , Count:  49 , Train ID: 230 , Loss=0.027 , Time=2.874\n",
      "512 , Count:  50 , Train ID: 96 , Loss=0.027 , Time=2.913\n",
      "512 , Count:  51 , Train ID: 130 , Loss=0.027 , Time=2.949\n",
      "512 , Count:  52 , Train ID: 200 , Loss=0.028 , Time=2.964\n",
      "512 , Count:  53 , Train ID: 76 , Loss=0.028 , Time=2.869\n",
      "512 , Count:  54 , Train ID: 157 , Loss=0.028 , Time=2.863\n",
      "512 , Count:  55 , Train ID: 92 , Loss=0.028 , Time=2.909\n",
      "512 , Count:  56 , Train ID: 39 , Loss=0.028 , Time=2.882\n",
      "512 , Count:  57 , Train ID: 129 , Loss=0.028 , Time=2.888\n",
      "512 , Count:  58 , Train ID: 158 , Loss=0.028 , Time=2.906\n",
      "512 , Count:  59 , Train ID: 51 , Loss=0.028 , Time=2.900\n",
      "512 , Count:  60 , Train ID: 26 , Loss=0.028 , Time=2.866\n",
      "512 , Count:  61 , Train ID: 194 , Loss=0.028 , Time=2.849\n",
      "512 , Count:  62 , Train ID: 160 , Loss=0.028 , Time=2.904\n",
      "512 , Count:  63 , Train ID: 58 , Loss=0.028 , Time=2.875\n",
      "512 , Count:  64 , Train ID: 154 , Loss=0.028 , Time=2.932\n",
      "512 , Count:  65 , Train ID: 102 , Loss=0.028 , Time=3.402\n",
      "512 , Count:  66 , Train ID: 66 , Loss=0.028 , Time=3.129\n",
      "512 , Count:  67 , Train ID: 95 , Loss=0.028 , Time=3.382\n",
      "512 , Count:  68 , Train ID: 174 , Loss=0.028 , Time=3.356\n",
      "512 , Count:  69 , Train ID: 78 , Loss=0.028 , Time=3.427\n",
      "512 , Count:  70 , Train ID: 104 , Loss=0.028 , Time=3.358\n",
      "512 , Count:  71 , Train ID: 46 , Loss=0.028 , Time=3.161\n",
      "512 , Count:  72 , Train ID: 110 , Loss=0.028 , Time=3.392\n",
      "512 , Count:  73 , Train ID: 222 , Loss=0.028 , Time=3.116\n",
      "512 , Count:  74 , Train ID: 149 , Loss=0.028 , Time=3.364\n",
      "512 , Count:  75 , Train ID: 161 , Loss=0.028 , Time=3.341\n",
      "512 , Count:  76 , Train ID: 1 , Loss=0.028 , Time=3.151\n",
      "512 , Count:  77 , Train ID: 41 , Loss=0.028 , Time=3.080\n",
      "512 , Count:  78 , Train ID: 18 , Loss=0.028 , Time=3.142\n",
      "512 , Count:  79 , Train ID: 88 , Loss=0.028 , Time=3.367\n",
      "512 , Count:  80 , Train ID: 142 , Loss=0.028 , Time=3.360\n",
      "512 , Count:  81 , Train ID: 91 , Loss=0.028 , Time=3.337\n",
      "512 , Count:  82 , Train ID: 221 , Loss=0.028 , Time=3.142\n",
      "512 , Count:  83 , Train ID: 189 , Loss=0.028 , Time=3.168\n",
      "512 , Count:  84 , Train ID: 9 , Loss=0.028 , Time=3.145\n",
      "512 , Count:  85 , Train ID: 99 , Loss=0.028 , Time=2.866\n",
      "512 , Count:  86 , Train ID: 184 , Loss=0.028 , Time=2.940\n",
      "512 , Count:  87 , Train ID: 179 , Loss=0.028 , Time=2.865\n",
      "512 , Count:  88 , Train ID: 209 , Loss=0.029 , Time=2.905\n",
      "512 , Count:  89 , Train ID: 65 , Loss=0.029 , Time=2.783\n",
      "512 , Count:  90 , Train ID: 215 , Loss=0.029 , Time=2.901\n",
      "512 , Count:  91 , Train ID: 98 , Loss=0.029 , Time=2.910\n",
      "512 , Count:  92 , Train ID: 190 , Loss=0.029 , Time=2.906\n",
      "512 , Count:  93 , Train ID: 225 , Loss=0.029 , Time=2.848\n",
      "512 , Count:  94 , Train ID: 151 , Loss=0.029 , Time=2.849\n",
      "512 , Count:  95 , Train ID: 14 , Loss=0.029 , Time=2.866\n",
      "512 , Count:  96 , Train ID: 186 , Loss=0.029 , Time=3.150\n",
      "512 , Count:  97 , Train ID: 4 , Loss=0.029 , Time=2.850\n",
      "512 , Count:  98 , Train ID: 73 , Loss=0.029 , Time=2.891\n",
      "512 , Count:  99 , Train ID: 131 , Loss=0.029 , Time=2.877\n",
      "512 , Count:  100 , Train ID: 212 , Loss=0.029 , Time=2.941\n",
      "512 , Count:  101 , Train ID: 202 , Loss=0.029 , Time=2.960\n",
      "512 , Count:  102 , Train ID: 57 , Loss=0.029 , Time=2.936\n",
      "512 , Count:  103 , Train ID: 29 , Loss=0.029 , Time=3.087\n",
      "512 , Count:  104 , Train ID: 124 , Loss=0.029 , Time=3.240\n",
      "512 , Count:  105 , Train ID: 28 , Loss=0.029 , Time=3.097\n",
      "512 , Count:  106 , Train ID: 83 , Loss=0.029 , Time=3.165\n",
      "512 , Count:  107 , Train ID: 146 , Loss=0.029 , Time=2.884\n",
      "512 , Count:  108 , Train ID: 33 , Loss=0.028 , Time=2.887\n",
      "512 , Count:  109 , Train ID: 75 , Loss=0.028 , Time=2.933\n",
      "512 , Count:  110 , Train ID: 10 , Loss=0.028 , Time=2.920\n",
      "512 , Count:  111 , Train ID: 223 , Loss=0.029 , Time=2.908\n",
      "512 , Count:  112 , Train ID: 113 , Loss=0.028 , Time=2.937\n",
      "512 , Count:  113 , Train ID: 114 , Loss=0.028 , Time=2.885\n",
      "512 , Count:  114 , Train ID: 207 , Loss=0.029 , Time=2.888\n",
      "512 , Count:  115 , Train ID: 197 , Loss=0.029 , Time=2.920\n",
      "512 , Count:  116 , Train ID: 159 , Loss=0.029 , Time=2.946\n",
      "512 , Count:  117 , Train ID: 137 , Loss=0.029 , Time=2.881\n",
      "512 , Count:  118 , Train ID: 19 , Loss=0.029 , Time=2.867\n",
      "512 , Count:  119 , Train ID: 2 , Loss=0.029 , Time=2.857\n",
      "512 , Count:  120 , Train ID: 128 , Loss=0.029 , Time=2.931\n",
      "512 , Count:  121 , Train ID: 145 , Loss=0.029 , Time=2.852\n",
      "512 , Count:  122 , Train ID: 122 , Loss=0.029 , Time=2.878\n",
      "512 , Count:  123 , Train ID: 56 , Loss=0.029 , Time=2.944\n",
      "512 , Count:  124 , Train ID: 108 , Loss=0.029 , Time=2.911\n",
      "512 , Count:  125 , Train ID: 100 , Loss=0.029 , Time=2.963\n",
      "512 , Count:  126 , Train ID: 86 , Loss=0.029 , Time=2.949\n",
      "512 , Count:  127 , Train ID: 132 , Loss=0.029 , Time=2.862\n",
      "512 , Count:  128 , Train ID: 112 , Loss=0.029 , Time=3.221\n",
      "512 , Count:  129 , Train ID: 90 , Loss=0.029 , Time=2.890\n",
      "512 , Count:  130 , Train ID: 168 , Loss=0.029 , Time=2.896\n",
      "512 , Count:  131 , Train ID: 144 , Loss=0.029 , Time=2.872\n",
      "512 , Count:  132 , Train ID: 182 , Loss=0.029 , Time=2.996\n",
      "512 , Count:  133 , Train ID: 148 , Loss=0.029 , Time=2.836\n",
      "512 , Count:  134 , Train ID: 70 , Loss=0.028 , Time=2.921\n",
      "512 , Count:  135 , Train ID: 155 , Loss=0.028 , Time=3.124\n",
      "512 , Count:  136 , Train ID: 133 , Loss=0.028 , Time=2.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 , Count:  137 , Train ID: 169 , Loss=0.028 , Time=2.880\n",
      "512 , Count:  138 , Train ID: 183 , Loss=0.028 , Time=2.848\n",
      "512 , Count:  139 , Train ID: 218 , Loss=0.028 , Time=2.896\n",
      "512 , Count:  140 , Train ID: 47 , Loss=0.028 , Time=2.893\n",
      "512 , Count:  141 , Train ID: 204 , Loss=0.028 , Time=2.985\n",
      "512 , Count:  142 , Train ID: 117 , Loss=0.028 , Time=2.855\n",
      "512 , Count:  143 , Train ID: 119 , Loss=0.028 , Time=2.925\n",
      "512 , Count:  144 , Train ID: 166 , Loss=0.028 , Time=2.876\n",
      "512 , Count:  145 , Train ID: 12 , Loss=0.028 , Time=2.897\n",
      "512 , Count:  146 , Train ID: 224 , Loss=0.028 , Time=2.881\n",
      "512 , Count:  147 , Train ID: 152 , Loss=0.028 , Time=2.948\n",
      "512 , Count:  148 , Train ID: 37 , Loss=0.028 , Time=2.838\n",
      "512 , Count:  149 , Train ID: 220 , Loss=0.028 , Time=2.928\n",
      "512 , Count:  150 , Train ID: 53 , Loss=0.028 , Time=2.899\n",
      "512 , Count:  151 , Train ID: 13 , Loss=0.028 , Time=2.908\n",
      "512 , Count:  152 , Train ID: 60 , Loss=0.028 , Time=2.921\n",
      "512 , Count:  153 , Train ID: 52 , Loss=0.028 , Time=2.879\n",
      "512 , Count:  154 , Train ID: 21 , Loss=0.028 , Time=2.827\n",
      "512 , Count:  155 , Train ID: 143 , Loss=0.028 , Time=2.905\n",
      "512 , Count:  156 , Train ID: 127 , Loss=0.028 , Time=2.919\n",
      "512 , Count:  157 , Train ID: 195 , Loss=0.028 , Time=3.088\n",
      "512 , Count:  158 , Train ID: 165 , Loss=0.028 , Time=3.169\n",
      "512 , Count:  159 , Train ID: 156 , Loss=0.028 , Time=3.493\n",
      "512 , Count:  160 , Train ID: 219 , Loss=0.029 , Time=3.147\n",
      "512 , Count:  161 , Train ID: 64 , Loss=0.029 , Time=3.198\n",
      "------------------------------------------------------------------\n",
      "Epoch: 512 to Epoch: 513------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "513 , Count:  1 , Train ID: 225 , Loss=0.029 , Time=3.020\n",
      "513 , Count:  2 , Train ID: 118 , Loss=0.029 , Time=2.006\n",
      "513 , Count:  3 , Train ID: 134 , Loss=0.029 , Time=1.947\n",
      "513 , Count:  4 , Train ID: 38 , Loss=0.029 , Time=2.978\n",
      "513 , Count:  5 , Train ID: 218 , Loss=0.029 , Time=1.989\n",
      "513 , Count:  6 , Train ID: 181 , Loss=0.028 , Time=3.071\n",
      "513 , Count:  7 , Train ID: 46 , Loss=0.028 , Time=3.071\n",
      "513 , Count:  8 , Train ID: 129 , Loss=0.028 , Time=1.969\n",
      "513 , Count:  9 , Train ID: 60 , Loss=0.028 , Time=3.036\n",
      "513 , Count:  10 , Train ID: 91 , Loss=0.028 , Time=1.989\n",
      "513 , Count:  11 , Train ID: 194 , Loss=0.028 , Time=1.963\n",
      "513 , Count:  12 , Train ID: 42 , Loss=0.028 , Time=3.047\n",
      "513 , Count:  13 , Train ID: 144 , Loss=0.028 , Time=1.884\n",
      "513 , Count:  14 , Train ID: 110 , Loss=0.028 , Time=2.004\n",
      "513 , Count:  15 , Train ID: 212 , Loss=0.028 , Time=3.066\n",
      "513 , Count:  16 , Train ID: 174 , Loss=0.028 , Time=2.003\n",
      "513 , Count:  17 , Train ID: 75 , Loss=0.028 , Time=2.011\n",
      "513 , Count:  18 , Train ID: 19 , Loss=0.028 , Time=1.928\n",
      "513 , Count:  19 , Train ID: 121 , Loss=0.028 , Time=1.984\n",
      "513 , Count:  20 , Train ID: 197 , Loss=0.028 , Time=1.974\n",
      "513 , Count:  21 , Train ID: 202 , Loss=0.028 , Time=3.060\n",
      "513 , Count:  22 , Train ID: 184 , Loss=0.028 , Time=1.997\n",
      "513 , Count:  23 , Train ID: 180 , Loss=0.028 , Time=3.144\n",
      "513 , Count:  24 , Train ID: 24 , Loss=0.028 , Time=3.086\n",
      "513 , Count:  25 , Train ID: 166 , Loss=0.028 , Time=1.891\n",
      "513 , Count:  26 , Train ID: 231 , Loss=0.028 , Time=2.023\n",
      "513 , Count:  27 , Train ID: 215 , Loss=0.029 , Time=3.086\n",
      "513 , Count:  28 , Train ID: 169 , Loss=0.029 , Time=2.029\n",
      "513 , Count:  29 , Train ID: 186 , Loss=0.029 , Time=3.127\n",
      "513 , Count:  30 , Train ID: 138 , Loss=0.029 , Time=2.067\n",
      "513 , Count:  31 , Train ID: 109 , Loss=0.029 , Time=1.896\n",
      "513 , Count:  32 , Train ID: 49 , Loss=0.029 , Time=1.986\n",
      "513 , Count:  33 , Train ID: 195 , Loss=0.029 , Time=1.943\n",
      "513 , Count:  34 , Train ID: 214 , Loss=0.028 , Time=1.957\n",
      "513 , Count:  35 , Train ID: 128 , Loss=0.029 , Time=2.014\n",
      "513 , Count:  36 , Train ID: 84 , Loss=0.029 , Time=2.067\n",
      "513 , Count:  37 , Train ID: 204 , Loss=0.029 , Time=2.056\n",
      "513 , Count:  38 , Train ID: 13 , Loss=0.029 , Time=2.014\n",
      "513 , Count:  39 , Train ID: 149 , Loss=0.029 , Time=1.938\n",
      "513 , Count:  40 , Train ID: 182 , Loss=0.029 , Time=3.080\n",
      "513 , Count:  41 , Train ID: 44 , Loss=0.029 , Time=3.004\n",
      "513 , Count:  42 , Train ID: 155 , Loss=0.029 , Time=2.045\n",
      "513 , Count:  43 , Train ID: 143 , Loss=0.029 , Time=1.915\n",
      "513 , Count:  44 , Train ID: 130 , Loss=0.029 , Time=1.912\n",
      "513 , Count:  45 , Train ID: 50 , Loss=0.029 , Time=3.110\n",
      "513 , Count:  46 , Train ID: 220 , Loss=0.029 , Time=2.922\n",
      "513 , Count:  47 , Train ID: 81 , Loss=0.029 , Time=2.018\n",
      "513 , Count:  48 , Train ID: 232 , Loss=0.029 , Time=2.989\n",
      "513 , Count:  49 , Train ID: 15 , Loss=0.029 , Time=2.042\n",
      "513 , Count:  50 , Train ID: 9 , Loss=0.029 , Time=2.101\n",
      "513 , Count:  51 , Train ID: 114 , Loss=0.029 , Time=2.076\n",
      "513 , Count:  52 , Train ID: 41 , Loss=0.029 , Time=3.011\n",
      "513 , Count:  53 , Train ID: 219 , Loss=0.029 , Time=2.052\n",
      "513 , Count:  54 , Train ID: 141 , Loss=0.029 , Time=2.029\n",
      "513 , Count:  55 , Train ID: 17 , Loss=0.029 , Time=2.970\n",
      "513 , Count:  56 , Train ID: 165 , Loss=0.029 , Time=1.900\n",
      "513 , Count:  57 , Train ID: 18 , Loss=0.029 , Time=1.931\n",
      "513 , Count:  58 , Train ID: 27 , Loss=0.029 , Time=2.062\n",
      "513 , Count:  59 , Train ID: 97 , Loss=0.029 , Time=2.007\n",
      "513 , Count:  60 , Train ID: 92 , Loss=0.029 , Time=1.916\n",
      "513 , Count:  61 , Train ID: 137 , Loss=0.029 , Time=2.003\n",
      "513 , Count:  62 , Train ID: 65 , Loss=0.029 , Time=2.847\n",
      "513 , Count:  63 , Train ID: 209 , Loss=0.029 , Time=2.916\n",
      "513 , Count:  64 , Train ID: 164 , Loss=0.029 , Time=1.963\n",
      "513 , Count:  65 , Train ID: 145 , Loss=0.029 , Time=1.951\n",
      "513 , Count:  66 , Train ID: 190 , Loss=0.029 , Time=3.015\n",
      "513 , Count:  67 , Train ID: 76 , Loss=0.029 , Time=2.033\n",
      "513 , Count:  68 , Train ID: 179 , Loss=0.029 , Time=1.958\n",
      "513 , Count:  69 , Train ID: 39 , Loss=0.029 , Time=1.940\n",
      "513 , Count:  70 , Train ID: 53 , Loss=0.029 , Time=2.995\n",
      "513 , Count:  71 , Train ID: 86 , Loss=0.029 , Time=2.013\n",
      "513 , Count:  72 , Train ID: 160 , Loss=0.029 , Time=2.069\n",
      "513 , Count:  73 , Train ID: 157 , Loss=0.029 , Time=2.102\n",
      "513 , Count:  74 , Train ID: 158 , Loss=0.029 , Time=2.002\n",
      "513 , Count:  75 , Train ID: 47 , Loss=0.029 , Time=2.991\n",
      "513 , Count:  76 , Train ID: 161 , Loss=0.029 , Time=2.015\n",
      "513 , Count:  77 , Train ID: 131 , Loss=0.029 , Time=1.937\n",
      "513 , Count:  78 , Train ID: 168 , Loss=0.029 , Time=2.067\n",
      "513 , Count:  79 , Train ID: 43 , Loss=0.029 , Time=1.985\n",
      "513 , Count:  80 , Train ID: 127 , Loss=0.029 , Time=2.041\n",
      "513 , Count:  81 , Train ID: 156 , Loss=0.029 , Time=1.975\n",
      "513 , Count:  82 , Train ID: 2 , Loss=0.029 , Time=1.934\n",
      "513 , Count:  83 , Train ID: 51 , Loss=0.029 , Time=2.064\n",
      "513 , Count:  84 , Train ID: 90 , Loss=0.030 , Time=1.988\n",
      "513 , Count:  85 , Train ID: 200 , Loss=0.029 , Time=2.077\n",
      "513 , Count:  86 , Train ID: 175 , Loss=0.029 , Time=2.056\n",
      "513 , Count:  87 , Train ID: 112 , Loss=0.029 , Time=2.052\n",
      "513 , Count:  88 , Train ID: 67 , Loss=0.029 , Time=2.975\n",
      "513 , Count:  89 , Train ID: 173 , Loss=0.029 , Time=2.018\n",
      "513 , Count:  90 , Train ID: 132 , Loss=0.029 , Time=1.959\n",
      "513 , Count:  91 , Train ID: 136 , Loss=0.029 , Time=2.046\n",
      "513 , Count:  92 , Train ID: 159 , Loss=0.029 , Time=1.973\n",
      "513 , Count:  93 , Train ID: 48 , Loss=0.029 , Time=1.994\n",
      "513 , Count:  94 , Train ID: 150 , Loss=0.029 , Time=1.951\n",
      "513 , Count:  95 , Train ID: 122 , Loss=0.029 , Time=2.074\n",
      "513 , Count:  96 , Train ID: 154 , Loss=0.029 , Time=2.029\n",
      "513 , Count:  97 , Train ID: 56 , Loss=0.029 , Time=1.984\n",
      "513 , Count:  98 , Train ID: 31 , Loss=0.029 , Time=1.981\n",
      "513 , Count:  99 , Train ID: 189 , Loss=0.029 , Time=3.080\n",
      "513 , Count:  100 , Train ID: 216 , Loss=0.029 , Time=2.020\n",
      "513 , Count:  101 , Train ID: 146 , Loss=0.029 , Time=2.005\n",
      "513 , Count:  102 , Train ID: 10 , Loss=0.029 , Time=2.967\n",
      "513 , Count:  103 , Train ID: 36 , Loss=0.029 , Time=2.885\n",
      "513 , Count:  104 , Train ID: 196 , Loss=0.029 , Time=3.001\n",
      "513 , Count:  105 , Train ID: 230 , Loss=0.029 , Time=2.928\n",
      "513 , Count:  106 , Train ID: 142 , Loss=0.029 , Time=1.992\n",
      "513 , Count:  107 , Train ID: 33 , Loss=0.029 , Time=3.024\n",
      "513 , Count:  108 , Train ID: 151 , Loss=0.029 , Time=2.004\n",
      "513 , Count:  109 , Train ID: 148 , Loss=0.029 , Time=1.958\n",
      "513 , Count:  110 , Train ID: 183 , Loss=0.029 , Time=2.947\n",
      "513 , Count:  111 , Train ID: 83 , Loss=0.029 , Time=2.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513 , Count:  112 , Train ID: 64 , Loss=0.029 , Time=3.070\n",
      "513 , Count:  113 , Train ID: 29 , Loss=0.030 , Time=2.864\n",
      "513 , Count:  114 , Train ID: 73 , Loss=0.030 , Time=1.918\n",
      "513 , Count:  115 , Train ID: 95 , Loss=0.030 , Time=1.943\n",
      "513 , Count:  116 , Train ID: 12 , Loss=0.030 , Time=2.947\n",
      "513 , Count:  117 , Train ID: 98 , Loss=0.030 , Time=1.895\n",
      "513 , Count:  118 , Train ID: 21 , Loss=0.030 , Time=1.913\n",
      "513 , Count:  119 , Train ID: 57 , Loss=0.030 , Time=2.916\n",
      "513 , Count:  120 , Train ID: 58 , Loss=0.030 , Time=2.969\n",
      "513 , Count:  121 , Train ID: 124 , Loss=0.030 , Time=1.990\n",
      "513 , Count:  122 , Train ID: 99 , Loss=0.030 , Time=2.078\n",
      "513 , Count:  123 , Train ID: 100 , Loss=0.030 , Time=2.009\n",
      "513 , Count:  124 , Train ID: 62 , Loss=0.030 , Time=3.075\n",
      "513 , Count:  125 , Train ID: 14 , Loss=0.030 , Time=2.063\n",
      "513 , Count:  126 , Train ID: 152 , Loss=0.030 , Time=2.089\n",
      "513 , Count:  127 , Train ID: 119 , Loss=0.030 , Time=1.894\n",
      "513 , Count:  128 , Train ID: 171 , Loss=0.030 , Time=2.154\n",
      "513 , Count:  129 , Train ID: 52 , Loss=0.030 , Time=2.938\n",
      "513 , Count:  130 , Train ID: 23 , Loss=0.030 , Time=3.034\n",
      "513 , Count:  131 , Train ID: 207 , Loss=0.030 , Time=3.179\n",
      "513 , Count:  132 , Train ID: 59 , Loss=0.030 , Time=3.098\n",
      "513 , Count:  133 , Train ID: 117 , Loss=0.030 , Time=1.940\n",
      "513 , Count:  134 , Train ID: 85 , Loss=0.030 , Time=2.015\n",
      "513 , Count:  135 , Train ID: 123 , Loss=0.030 , Time=1.937\n",
      "513 , Count:  136 , Train ID: 78 , Loss=0.030 , Time=1.977\n",
      "513 , Count:  137 , Train ID: 222 , Loss=0.030 , Time=1.997\n",
      "513 , Count:  138 , Train ID: 224 , Loss=0.030 , Time=3.032\n",
      "513 , Count:  139 , Train ID: 28 , Loss=0.030 , Time=1.918\n",
      "513 , Count:  140 , Train ID: 223 , Loss=0.030 , Time=2.989\n",
      "513 , Count:  141 , Train ID: 133 , Loss=0.030 , Time=1.958\n",
      "513 , Count:  142 , Train ID: 1 , Loss=0.030 , Time=1.981\n",
      "513 , Count:  143 , Train ID: 66 , Loss=0.030 , Time=1.942\n",
      "513 , Count:  144 , Train ID: 135 , Loss=0.030 , Time=1.992\n",
      "513 , Count:  145 , Train ID: 113 , Loss=0.030 , Time=1.957\n",
      "513 , Count:  146 , Train ID: 26 , Loss=0.030 , Time=2.011\n",
      "513 , Count:  147 , Train ID: 102 , Loss=0.030 , Time=1.976\n",
      "513 , Count:  148 , Train ID: 70 , Loss=0.030 , Time=3.046\n",
      "513 , Count:  149 , Train ID: 206 , Loss=0.030 , Time=3.080\n",
      "513 , Count:  150 , Train ID: 104 , Loss=0.030 , Time=1.992\n",
      "513 , Count:  151 , Train ID: 63 , Loss=0.030 , Time=3.108\n",
      "513 , Count:  152 , Train ID: 94 , Loss=0.030 , Time=1.976\n",
      "513 , Count:  153 , Train ID: 71 , Loss=0.030 , Time=3.008\n",
      "513 , Count:  154 , Train ID: 88 , Loss=0.030 , Time=2.067\n",
      "513 , Count:  155 , Train ID: 205 , Loss=0.030 , Time=3.037\n",
      "513 , Count:  156 , Train ID: 96 , Loss=0.030 , Time=1.955\n",
      "513 , Count:  157 , Train ID: 4 , Loss=0.030 , Time=2.994\n",
      "513 , Count:  158 , Train ID: 72 , Loss=0.030 , Time=1.959\n",
      "513 , Count:  159 , Train ID: 221 , Loss=0.030 , Time=3.035\n",
      "513 , Count:  160 , Train ID: 108 , Loss=0.030 , Time=1.913\n",
      "513 , Count:  161 , Train ID: 37 , Loss=0.030 , Time=2.019\n",
      "------------------------------------------------------------------\n",
      "Epoch: 513 to Epoch: 514------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "514 , Count:  1 , Train ID: 148 , Loss=0.030 , Time=1.989\n",
      "514 , Count:  2 , Train ID: 221 , Loss=0.030 , Time=3.107\n",
      "514 , Count:  3 , Train ID: 72 , Loss=0.030 , Time=2.048\n",
      "514 , Count:  4 , Train ID: 33 , Loss=0.030 , Time=1.945\n",
      "514 , Count:  5 , Train ID: 122 , Loss=0.030 , Time=2.004\n",
      "514 , Count:  6 , Train ID: 130 , Loss=0.030 , Time=2.062\n",
      "514 , Count:  7 , Train ID: 21 , Loss=0.030 , Time=3.072\n",
      "514 , Count:  8 , Train ID: 76 , Loss=0.030 , Time=1.996\n",
      "514 , Count:  9 , Train ID: 14 , Loss=0.030 , Time=2.076\n",
      "514 , Count:  10 , Train ID: 113 , Loss=0.030 , Time=2.036\n",
      "514 , Count:  11 , Train ID: 112 , Loss=0.030 , Time=1.995\n",
      "514 , Count:  12 , Train ID: 230 , Loss=0.030 , Time=3.193\n",
      "514 , Count:  13 , Train ID: 134 , Loss=0.030 , Time=1.928\n",
      "514 , Count:  14 , Train ID: 225 , Loss=0.030 , Time=2.008\n",
      "514 , Count:  15 , Train ID: 207 , Loss=0.030 , Time=3.033\n",
      "514 , Count:  16 , Train ID: 85 , Loss=0.030 , Time=1.939\n",
      "514 , Count:  17 , Train ID: 66 , Loss=0.030 , Time=3.055\n",
      "514 , Count:  18 , Train ID: 224 , Loss=0.030 , Time=3.107\n",
      "514 , Count:  19 , Train ID: 42 , Loss=0.030 , Time=1.900\n",
      "514 , Count:  20 , Train ID: 180 , Loss=0.030 , Time=1.969\n",
      "514 , Count:  21 , Train ID: 150 , Loss=0.030 , Time=1.998\n",
      "514 , Count:  22 , Train ID: 29 , Loss=0.030 , Time=2.017\n",
      "514 , Count:  23 , Train ID: 41 , Loss=0.030 , Time=1.974\n",
      "514 , Count:  24 , Train ID: 64 , Loss=0.030 , Time=2.007\n",
      "514 , Count:  25 , Train ID: 195 , Loss=0.030 , Time=1.944\n",
      "514 , Count:  26 , Train ID: 136 , Loss=0.030 , Time=1.937\n",
      "514 , Count:  27 , Train ID: 17 , Loss=0.030 , Time=2.002\n",
      "514 , Count:  28 , Train ID: 158 , Loss=0.030 , Time=1.998\n",
      "514 , Count:  29 , Train ID: 75 , Loss=0.030 , Time=2.010\n",
      "514 , Count:  30 , Train ID: 83 , Loss=0.030 , Time=1.915\n",
      "514 , Count:  31 , Train ID: 132 , Loss=0.030 , Time=1.952\n",
      "514 , Count:  32 , Train ID: 183 , Loss=0.030 , Time=3.050\n",
      "514 , Count:  33 , Train ID: 166 , Loss=0.030 , Time=1.918\n",
      "514 , Count:  34 , Train ID: 143 , Loss=0.030 , Time=1.929\n",
      "514 , Count:  35 , Train ID: 169 , Loss=0.030 , Time=1.982\n",
      "514 , Count:  36 , Train ID: 220 , Loss=0.030 , Time=1.968\n",
      "514 , Count:  37 , Train ID: 219 , Loss=0.030 , Time=3.150\n",
      "514 , Count:  38 , Train ID: 24 , Loss=0.030 , Time=2.044\n",
      "514 , Count:  39 , Train ID: 94 , Loss=0.030 , Time=1.982\n",
      "514 , Count:  40 , Train ID: 204 , Loss=0.030 , Time=3.080\n",
      "514 , Count:  41 , Train ID: 231 , Loss=0.030 , Time=2.013\n",
      "514 , Count:  42 , Train ID: 114 , Loss=0.030 , Time=1.943\n",
      "514 , Count:  43 , Train ID: 9 , Loss=0.030 , Time=1.965\n",
      "514 , Count:  44 , Train ID: 37 , Loss=0.030 , Time=3.131\n",
      "514 , Count:  45 , Train ID: 65 , Loss=0.030 , Time=1.920\n",
      "514 , Count:  46 , Train ID: 117 , Loss=0.030 , Time=1.992\n",
      "514 , Count:  47 , Train ID: 118 , Loss=0.030 , Time=2.012\n",
      "514 , Count:  48 , Train ID: 63 , Loss=0.030 , Time=1.990\n",
      "514 , Count:  49 , Train ID: 141 , Loss=0.030 , Time=1.910\n",
      "514 , Count:  50 , Train ID: 182 , Loss=0.030 , Time=1.965\n",
      "514 , Count:  51 , Train ID: 10 , Loss=0.030 , Time=1.987\n",
      "514 , Count:  52 , Train ID: 57 , Loss=0.030 , Time=1.951\n",
      "514 , Count:  53 , Train ID: 216 , Loss=0.030 , Time=3.040\n",
      "514 , Count:  54 , Train ID: 48 , Loss=0.030 , Time=3.129\n",
      "514 , Count:  55 , Train ID: 52 , Loss=0.030 , Time=1.982\n",
      "514 , Count:  56 , Train ID: 43 , Loss=0.030 , Time=1.991\n",
      "514 , Count:  57 , Train ID: 36 , Loss=0.030 , Time=1.968\n",
      "514 , Count:  58 , Train ID: 232 , Loss=0.030 , Time=2.047\n",
      "514 , Count:  59 , Train ID: 133 , Loss=0.030 , Time=2.040\n",
      "514 , Count:  60 , Train ID: 160 , Loss=0.030 , Time=1.957\n",
      "514 , Count:  61 , Train ID: 97 , Loss=0.030 , Time=2.030\n",
      "514 , Count:  62 , Train ID: 62 , Loss=0.030 , Time=2.078\n",
      "514 , Count:  63 , Train ID: 88 , Loss=0.030 , Time=1.968\n",
      "514 , Count:  64 , Train ID: 212 , Loss=0.030 , Time=3.145\n",
      "514 , Count:  65 , Train ID: 129 , Loss=0.030 , Time=1.965\n",
      "514 , Count:  66 , Train ID: 206 , Loss=0.030 , Time=3.155\n",
      "514 , Count:  67 , Train ID: 215 , Loss=0.030 , Time=3.049\n",
      "514 , Count:  68 , Train ID: 124 , Loss=0.030 , Time=1.926\n",
      "514 , Count:  69 , Train ID: 175 , Loss=0.030 , Time=1.971\n",
      "514 , Count:  70 , Train ID: 202 , Loss=0.030 , Time=1.960\n",
      "514 , Count:  71 , Train ID: 91 , Loss=0.030 , Time=2.032\n",
      "514 , Count:  72 , Train ID: 168 , Loss=0.030 , Time=1.950\n",
      "514 , Count:  73 , Train ID: 19 , Loss=0.030 , Time=1.961\n",
      "514 , Count:  74 , Train ID: 121 , Loss=0.030 , Time=2.035\n",
      "514 , Count:  75 , Train ID: 222 , Loss=0.030 , Time=1.977\n",
      "514 , Count:  76 , Train ID: 151 , Loss=0.030 , Time=1.961\n",
      "514 , Count:  77 , Train ID: 15 , Loss=0.030 , Time=2.009\n",
      "514 , Count:  78 , Train ID: 108 , Loss=0.030 , Time=1.943\n",
      "514 , Count:  79 , Train ID: 49 , Loss=0.030 , Time=1.952\n",
      "514 , Count:  80 , Train ID: 149 , Loss=0.030 , Time=2.057\n",
      "514 , Count:  81 , Train ID: 189 , Loss=0.030 , Time=3.073\n",
      "514 , Count:  82 , Train ID: 26 , Loss=0.030 , Time=1.944\n",
      "514 , Count:  83 , Train ID: 137 , Loss=0.030 , Time=2.025\n",
      "514 , Count:  84 , Train ID: 58 , Loss=0.030 , Time=1.990\n",
      "514 , Count:  85 , Train ID: 146 , Loss=0.030 , Time=2.007\n",
      "514 , Count:  86 , Train ID: 86 , Loss=0.030 , Time=1.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514 , Count:  87 , Train ID: 53 , Loss=0.030 , Time=1.965\n",
      "514 , Count:  88 , Train ID: 51 , Loss=0.030 , Time=2.082\n",
      "514 , Count:  89 , Train ID: 205 , Loss=0.030 , Time=2.024\n",
      "514 , Count:  90 , Train ID: 196 , Loss=0.030 , Time=2.932\n",
      "514 , Count:  91 , Train ID: 78 , Loss=0.030 , Time=2.051\n",
      "514 , Count:  92 , Train ID: 161 , Loss=0.030 , Time=1.945\n",
      "514 , Count:  93 , Train ID: 131 , Loss=0.030 , Time=2.033\n",
      "514 , Count:  94 , Train ID: 31 , Loss=0.030 , Time=2.933\n",
      "514 , Count:  95 , Train ID: 138 , Loss=0.030 , Time=2.003\n",
      "514 , Count:  96 , Train ID: 194 , Loss=0.029 , Time=3.061\n",
      "514 , Count:  97 , Train ID: 164 , Loss=0.029 , Time=1.995\n",
      "514 , Count:  98 , Train ID: 12 , Loss=0.029 , Time=1.910\n",
      "514 , Count:  99 , Train ID: 56 , Loss=0.029 , Time=2.000\n",
      "514 , Count:  100 , Train ID: 119 , Loss=0.029 , Time=1.970\n",
      "514 , Count:  101 , Train ID: 46 , Loss=0.030 , Time=2.001\n",
      "514 , Count:  102 , Train ID: 104 , Loss=0.030 , Time=2.034\n",
      "514 , Count:  103 , Train ID: 71 , Loss=0.030 , Time=1.944\n",
      "514 , Count:  104 , Train ID: 59 , Loss=0.030 , Time=2.071\n",
      "514 , Count:  105 , Train ID: 218 , Loss=0.030 , Time=2.006\n",
      "514 , Count:  106 , Train ID: 50 , Loss=0.030 , Time=2.006\n",
      "514 , Count:  107 , Train ID: 173 , Loss=0.030 , Time=1.945\n",
      "514 , Count:  108 , Train ID: 152 , Loss=0.030 , Time=2.055\n",
      "514 , Count:  109 , Train ID: 90 , Loss=0.030 , Time=2.029\n",
      "514 , Count:  110 , Train ID: 200 , Loss=0.030 , Time=2.999\n",
      "514 , Count:  111 , Train ID: 39 , Loss=0.030 , Time=2.922\n",
      "514 , Count:  112 , Train ID: 144 , Loss=0.030 , Time=2.011\n",
      "514 , Count:  113 , Train ID: 174 , Loss=0.030 , Time=1.973\n",
      "514 , Count:  114 , Train ID: 223 , Loss=0.030 , Time=2.057\n",
      "514 , Count:  115 , Train ID: 156 , Loss=0.030 , Time=2.067\n",
      "514 , Count:  116 , Train ID: 84 , Loss=0.030 , Time=1.939\n",
      "514 , Count:  117 , Train ID: 154 , Loss=0.030 , Time=2.136\n",
      "514 , Count:  118 , Train ID: 47 , Loss=0.030 , Time=1.983\n",
      "514 , Count:  119 , Train ID: 145 , Loss=0.030 , Time=1.964\n",
      "514 , Count:  120 , Train ID: 81 , Loss=0.030 , Time=2.008\n",
      "514 , Count:  121 , Train ID: 13 , Loss=0.030 , Time=2.050\n",
      "514 , Count:  122 , Train ID: 155 , Loss=0.030 , Time=2.019\n",
      "514 , Count:  123 , Train ID: 179 , Loss=0.030 , Time=2.879\n",
      "514 , Count:  124 , Train ID: 92 , Loss=0.030 , Time=1.933\n",
      "514 , Count:  125 , Train ID: 209 , Loss=0.030 , Time=3.002\n",
      "514 , Count:  126 , Train ID: 99 , Loss=0.030 , Time=1.950\n",
      "514 , Count:  127 , Train ID: 184 , Loss=0.030 , Time=1.949\n",
      "514 , Count:  128 , Train ID: 100 , Loss=0.030 , Time=1.921\n",
      "514 , Count:  129 , Train ID: 135 , Loss=0.030 , Time=2.067\n",
      "514 , Count:  130 , Train ID: 27 , Loss=0.030 , Time=2.919\n",
      "514 , Count:  131 , Train ID: 142 , Loss=0.030 , Time=1.943\n",
      "514 , Count:  132 , Train ID: 44 , Loss=0.030 , Time=1.995\n",
      "514 , Count:  133 , Train ID: 109 , Loss=0.030 , Time=2.087\n",
      "514 , Count:  134 , Train ID: 70 , Loss=0.030 , Time=1.949\n",
      "514 , Count:  135 , Train ID: 4 , Loss=0.030 , Time=2.026\n",
      "514 , Count:  136 , Train ID: 127 , Loss=0.030 , Time=2.039\n",
      "514 , Count:  137 , Train ID: 165 , Loss=0.030 , Time=1.984\n",
      "514 , Count:  138 , Train ID: 128 , Loss=0.030 , Time=1.988\n",
      "514 , Count:  139 , Train ID: 159 , Loss=0.030 , Time=1.971\n",
      "514 , Count:  140 , Train ID: 23 , Loss=0.030 , Time=2.035\n",
      "514 , Count:  141 , Train ID: 171 , Loss=0.030 , Time=1.920\n",
      "514 , Count:  142 , Train ID: 73 , Loss=0.030 , Time=1.935\n",
      "514 , Count:  143 , Train ID: 214 , Loss=0.030 , Time=2.041\n",
      "514 , Count:  144 , Train ID: 18 , Loss=0.030 , Time=1.948\n",
      "514 , Count:  145 , Train ID: 186 , Loss=0.030 , Time=2.069\n",
      "514 , Count:  146 , Train ID: 98 , Loss=0.030 , Time=1.990\n",
      "514 , Count:  147 , Train ID: 190 , Loss=0.030 , Time=1.980\n",
      "514 , Count:  148 , Train ID: 102 , Loss=0.030 , Time=1.964\n",
      "514 , Count:  149 , Train ID: 28 , Loss=0.030 , Time=1.861\n",
      "514 , Count:  150 , Train ID: 60 , Loss=0.030 , Time=2.018\n",
      "514 , Count:  151 , Train ID: 110 , Loss=0.030 , Time=1.963\n",
      "514 , Count:  152 , Train ID: 197 , Loss=0.030 , Time=2.963\n",
      "514 , Count:  153 , Train ID: 123 , Loss=0.030 , Time=1.955\n",
      "514 , Count:  154 , Train ID: 95 , Loss=0.030 , Time=2.012\n",
      "514 , Count:  155 , Train ID: 2 , Loss=0.030 , Time=3.001\n",
      "514 , Count:  156 , Train ID: 38 , Loss=0.030 , Time=1.990\n",
      "514 , Count:  157 , Train ID: 96 , Loss=0.030 , Time=1.930\n",
      "514 , Count:  158 , Train ID: 67 , Loss=0.031 , Time=1.939\n",
      "514 , Count:  159 , Train ID: 181 , Loss=0.031 , Time=2.905\n",
      "514 , Count:  160 , Train ID: 157 , Loss=0.031 , Time=1.930\n",
      "514 , Count:  161 , Train ID: 1 , Loss=0.031 , Time=2.049\n",
      "------------------------------------------------------------------\n",
      "Epoch: 514 to Epoch: 515------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "515 , Count:  1 , Train ID: 73 , Loss=0.031 , Time=2.005\n",
      "515 , Count:  2 , Train ID: 21 , Loss=0.031 , Time=1.922\n",
      "515 , Count:  3 , Train ID: 214 , Loss=0.031 , Time=3.048\n",
      "515 , Count:  4 , Train ID: 57 , Loss=0.031 , Time=1.915\n",
      "515 , Count:  5 , Train ID: 220 , Loss=0.031 , Time=2.997\n",
      "515 , Count:  6 , Train ID: 164 , Loss=0.031 , Time=2.034\n",
      "515 , Count:  7 , Train ID: 90 , Loss=0.031 , Time=1.997\n",
      "515 , Count:  8 , Train ID: 154 , Loss=0.031 , Time=2.080\n",
      "515 , Count:  9 , Train ID: 135 , Loss=0.031 , Time=1.969\n",
      "515 , Count:  10 , Train ID: 225 , Loss=0.031 , Time=1.964\n",
      "515 , Count:  11 , Train ID: 59 , Loss=0.031 , Time=1.953\n",
      "515 , Count:  12 , Train ID: 67 , Loss=0.031 , Time=1.988\n",
      "515 , Count:  13 , Train ID: 14 , Loss=0.031 , Time=3.050\n",
      "515 , Count:  14 , Train ID: 102 , Loss=0.031 , Time=2.033\n",
      "515 , Count:  15 , Train ID: 81 , Loss=0.030 , Time=2.009\n",
      "515 , Count:  16 , Train ID: 70 , Loss=0.030 , Time=1.918\n",
      "515 , Count:  17 , Train ID: 50 , Loss=0.031 , Time=2.025\n",
      "515 , Count:  18 , Train ID: 91 , Loss=0.031 , Time=1.970\n",
      "515 , Count:  19 , Train ID: 166 , Loss=0.031 , Time=1.938\n",
      "515 , Count:  20 , Train ID: 62 , Loss=0.031 , Time=2.048\n",
      "515 , Count:  21 , Train ID: 33 , Loss=0.031 , Time=1.928\n",
      "515 , Count:  22 , Train ID: 151 , Loss=0.031 , Time=2.065\n",
      "515 , Count:  23 , Train ID: 159 , Loss=0.031 , Time=1.959\n",
      "515 , Count:  24 , Train ID: 165 , Loss=0.031 , Time=2.025\n",
      "515 , Count:  25 , Train ID: 218 , Loss=0.031 , Time=3.132\n",
      "515 , Count:  26 , Train ID: 63 , Loss=0.031 , Time=2.070\n",
      "515 , Count:  27 , Train ID: 137 , Loss=0.031 , Time=2.078\n",
      "515 , Count:  28 , Train ID: 24 , Loss=0.031 , Time=1.931\n",
      "515 , Count:  29 , Train ID: 56 , Loss=0.031 , Time=2.060\n",
      "515 , Count:  30 , Train ID: 173 , Loss=0.030 , Time=1.937\n",
      "515 , Count:  31 , Train ID: 4 , Loss=0.030 , Time=1.974\n",
      "515 , Count:  32 , Train ID: 205 , Loss=0.030 , Time=2.917\n",
      "515 , Count:  33 , Train ID: 143 , Loss=0.030 , Time=1.950\n",
      "515 , Count:  34 , Train ID: 84 , Loss=0.030 , Time=2.032\n",
      "515 , Count:  35 , Train ID: 128 , Loss=0.031 , Time=1.990\n",
      "515 , Count:  36 , Train ID: 78 , Loss=0.031 , Time=2.012\n",
      "515 , Count:  37 , Train ID: 160 , Loss=0.031 , Time=1.989\n",
      "515 , Count:  38 , Train ID: 204 , Loss=0.031 , Time=2.008\n",
      "515 , Count:  39 , Train ID: 212 , Loss=0.031 , Time=1.946\n",
      "515 , Count:  40 , Train ID: 124 , Loss=0.031 , Time=1.975\n",
      "515 , Count:  41 , Train ID: 65 , Loss=0.031 , Time=2.077\n",
      "515 , Count:  42 , Train ID: 37 , Loss=0.031 , Time=2.031\n",
      "515 , Count:  43 , Train ID: 129 , Loss=0.031 , Time=1.963\n",
      "515 , Count:  44 , Train ID: 200 , Loss=0.030 , Time=2.018\n",
      "515 , Count:  45 , Train ID: 190 , Loss=0.030 , Time=2.026\n",
      "515 , Count:  46 , Train ID: 161 , Loss=0.030 , Time=2.003\n",
      "515 , Count:  47 , Train ID: 12 , Loss=0.030 , Time=1.976\n",
      "515 , Count:  48 , Train ID: 17 , Loss=0.030 , Time=1.993\n",
      "515 , Count:  49 , Train ID: 119 , Loss=0.030 , Time=1.903\n",
      "515 , Count:  50 , Train ID: 118 , Loss=0.030 , Time=1.999\n",
      "515 , Count:  51 , Train ID: 19 , Loss=0.030 , Time=1.922\n",
      "515 , Count:  52 , Train ID: 123 , Loss=0.030 , Time=1.933\n",
      "515 , Count:  53 , Train ID: 94 , Loss=0.030 , Time=2.004\n",
      "515 , Count:  54 , Train ID: 132 , Loss=0.030 , Time=1.983\n",
      "515 , Count:  55 , Train ID: 169 , Loss=0.030 , Time=1.922\n",
      "515 , Count:  56 , Train ID: 52 , Loss=0.030 , Time=1.995\n",
      "515 , Count:  57 , Train ID: 122 , Loss=0.030 , Time=1.912\n",
      "515 , Count:  58 , Train ID: 121 , Loss=0.030 , Time=1.914\n",
      "515 , Count:  59 , Train ID: 100 , Loss=0.030 , Time=2.013\n",
      "515 , Count:  60 , Train ID: 72 , Loss=0.030 , Time=1.934\n",
      "515 , Count:  61 , Train ID: 171 , Loss=0.030 , Time=2.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515 , Count:  62 , Train ID: 183 , Loss=0.030 , Time=1.990\n",
      "515 , Count:  63 , Train ID: 75 , Loss=0.030 , Time=1.969\n",
      "515 , Count:  64 , Train ID: 42 , Loss=0.030 , Time=2.022\n",
      "515 , Count:  65 , Train ID: 138 , Loss=0.030 , Time=2.003\n",
      "515 , Count:  66 , Train ID: 104 , Loss=0.030 , Time=1.971\n",
      "515 , Count:  67 , Train ID: 230 , Loss=0.030 , Time=2.064\n",
      "515 , Count:  68 , Train ID: 219 , Loss=0.030 , Time=2.952\n",
      "515 , Count:  69 , Train ID: 71 , Loss=0.030 , Time=1.955\n",
      "515 , Count:  70 , Train ID: 23 , Loss=0.030 , Time=2.042\n",
      "515 , Count:  71 , Train ID: 15 , Loss=0.030 , Time=1.989\n",
      "515 , Count:  72 , Train ID: 96 , Loss=0.030 , Time=1.941\n",
      "515 , Count:  73 , Train ID: 48 , Loss=0.030 , Time=2.008\n",
      "515 , Count:  74 , Train ID: 60 , Loss=0.030 , Time=1.983\n",
      "515 , Count:  75 , Train ID: 39 , Loss=0.030 , Time=1.984\n",
      "515 , Count:  76 , Train ID: 112 , Loss=0.030 , Time=1.983\n",
      "515 , Count:  77 , Train ID: 97 , Loss=0.030 , Time=2.009\n",
      "515 , Count:  78 , Train ID: 197 , Loss=0.030 , Time=1.967\n",
      "515 , Count:  79 , Train ID: 224 , Loss=0.030 , Time=1.969\n",
      "515 , Count:  80 , Train ID: 215 , Loss=0.030 , Time=2.011\n",
      "515 , Count:  81 , Train ID: 47 , Loss=0.030 , Time=1.996\n",
      "515 , Count:  82 , Train ID: 174 , Loss=0.030 , Time=2.015\n",
      "515 , Count:  83 , Train ID: 99 , Loss=0.030 , Time=1.907\n",
      "515 , Count:  84 , Train ID: 53 , Loss=0.030 , Time=1.992\n",
      "515 , Count:  85 , Train ID: 26 , Loss=0.030 , Time=2.007\n",
      "515 , Count:  86 , Train ID: 141 , Loss=0.030 , Time=2.041\n",
      "515 , Count:  87 , Train ID: 209 , Loss=0.030 , Time=2.036\n",
      "515 , Count:  88 , Train ID: 127 , Loss=0.030 , Time=1.963\n",
      "515 , Count:  89 , Train ID: 142 , Loss=0.030 , Time=2.022\n",
      "515 , Count:  90 , Train ID: 196 , Loss=0.030 , Time=1.939\n",
      "515 , Count:  91 , Train ID: 38 , Loss=0.030 , Time=2.081\n",
      "515 , Count:  92 , Train ID: 184 , Loss=0.030 , Time=3.020\n",
      "515 , Count:  93 , Train ID: 76 , Loss=0.030 , Time=1.986\n",
      "515 , Count:  94 , Train ID: 232 , Loss=0.030 , Time=2.011\n",
      "515 , Count:  95 , Train ID: 221 , Loss=0.030 , Time=1.982\n",
      "515 , Count:  96 , Train ID: 156 , Loss=0.030 , Time=1.987\n",
      "515 , Count:  97 , Train ID: 51 , Loss=0.030 , Time=1.967\n",
      "515 , Count:  98 , Train ID: 216 , Loss=0.030 , Time=2.023\n",
      "515 , Count:  99 , Train ID: 179 , Loss=0.030 , Time=1.938\n",
      "515 , Count:  100 , Train ID: 146 , Loss=0.030 , Time=2.023\n",
      "515 , Count:  101 , Train ID: 13 , Loss=0.030 , Time=2.927\n",
      "515 , Count:  102 , Train ID: 9 , Loss=0.030 , Time=1.938\n",
      "515 , Count:  103 , Train ID: 136 , Loss=0.030 , Time=2.080\n",
      "515 , Count:  104 , Train ID: 44 , Loss=0.030 , Time=2.006\n",
      "515 , Count:  105 , Train ID: 133 , Loss=0.030 , Time=2.061\n",
      "515 , Count:  106 , Train ID: 222 , Loss=0.030 , Time=3.036\n",
      "515 , Count:  107 , Train ID: 158 , Loss=0.030 , Time=1.967\n",
      "515 , Count:  108 , Train ID: 189 , Loss=0.030 , Time=2.127\n",
      "515 , Count:  109 , Train ID: 145 , Loss=0.030 , Time=2.089\n",
      "515 , Count:  110 , Train ID: 202 , Loss=0.030 , Time=1.996\n",
      "515 , Count:  111 , Train ID: 149 , Loss=0.030 , Time=2.044\n",
      "515 , Count:  112 , Train ID: 85 , Loss=0.031 , Time=2.038\n",
      "515 , Count:  113 , Train ID: 64 , Loss=0.031 , Time=2.048\n",
      "515 , Count:  114 , Train ID: 131 , Loss=0.031 , Time=1.918\n",
      "515 , Count:  115 , Train ID: 180 , Loss=0.031 , Time=1.950\n",
      "515 , Count:  116 , Train ID: 49 , Loss=0.031 , Time=1.906\n",
      "515 , Count:  117 , Train ID: 207 , Loss=0.031 , Time=1.937\n",
      "515 , Count:  118 , Train ID: 29 , Loss=0.031 , Time=2.089\n",
      "515 , Count:  119 , Train ID: 46 , Loss=0.031 , Time=2.082\n",
      "515 , Count:  120 , Train ID: 155 , Loss=0.031 , Time=1.908\n",
      "515 , Count:  121 , Train ID: 182 , Loss=0.031 , Time=2.099\n",
      "515 , Count:  122 , Train ID: 1 , Loss=0.031 , Time=2.986\n",
      "515 , Count:  123 , Train ID: 181 , Loss=0.031 , Time=2.040\n",
      "515 , Count:  124 , Train ID: 206 , Loss=0.031 , Time=2.085\n",
      "515 , Count:  125 , Train ID: 109 , Loss=0.031 , Time=2.053\n",
      "515 , Count:  126 , Train ID: 186 , Loss=0.031 , Time=2.050\n",
      "515 , Count:  127 , Train ID: 2 , Loss=0.031 , Time=2.050\n",
      "515 , Count:  128 , Train ID: 83 , Loss=0.031 , Time=1.979\n",
      "515 , Count:  129 , Train ID: 95 , Loss=0.031 , Time=2.021\n",
      "515 , Count:  130 , Train ID: 152 , Loss=0.031 , Time=2.044\n",
      "515 , Count:  131 , Train ID: 58 , Loss=0.031 , Time=2.056\n",
      "515 , Count:  132 , Train ID: 113 , Loss=0.031 , Time=1.941\n",
      "515 , Count:  133 , Train ID: 117 , Loss=0.031 , Time=1.947\n",
      "515 , Count:  134 , Train ID: 144 , Loss=0.031 , Time=2.018\n",
      "515 , Count:  135 , Train ID: 194 , Loss=0.031 , Time=2.078\n",
      "515 , Count:  136 , Train ID: 108 , Loss=0.031 , Time=1.962\n",
      "515 , Count:  137 , Train ID: 88 , Loss=0.031 , Time=2.040\n",
      "515 , Count:  138 , Train ID: 157 , Loss=0.031 , Time=2.044\n",
      "515 , Count:  139 , Train ID: 18 , Loss=0.031 , Time=3.104\n",
      "515 , Count:  140 , Train ID: 10 , Loss=0.031 , Time=2.071\n",
      "515 , Count:  141 , Train ID: 28 , Loss=0.031 , Time=1.951\n",
      "515 , Count:  142 , Train ID: 41 , Loss=0.031 , Time=1.995\n",
      "515 , Count:  143 , Train ID: 66 , Loss=0.031 , Time=2.025\n",
      "515 , Count:  144 , Train ID: 86 , Loss=0.031 , Time=1.932\n",
      "515 , Count:  145 , Train ID: 130 , Loss=0.031 , Time=2.047\n",
      "515 , Count:  146 , Train ID: 98 , Loss=0.031 , Time=2.016\n",
      "515 , Count:  147 , Train ID: 27 , Loss=0.031 , Time=2.049\n",
      "515 , Count:  148 , Train ID: 231 , Loss=0.031 , Time=2.017\n",
      "515 , Count:  149 , Train ID: 31 , Loss=0.031 , Time=1.972\n",
      "515 , Count:  150 , Train ID: 92 , Loss=0.031 , Time=2.078\n",
      "515 , Count:  151 , Train ID: 175 , Loss=0.031 , Time=2.071\n",
      "515 , Count:  152 , Train ID: 168 , Loss=0.031 , Time=2.038\n",
      "515 , Count:  153 , Train ID: 223 , Loss=0.031 , Time=1.959\n",
      "515 , Count:  154 , Train ID: 195 , Loss=0.031 , Time=3.008\n",
      "515 , Count:  155 , Train ID: 110 , Loss=0.031 , Time=1.930\n",
      "515 , Count:  156 , Train ID: 148 , Loss=0.031 , Time=1.940\n",
      "515 , Count:  157 , Train ID: 43 , Loss=0.031 , Time=2.074\n",
      "515 , Count:  158 , Train ID: 150 , Loss=0.031 , Time=2.044\n",
      "515 , Count:  159 , Train ID: 36 , Loss=0.031 , Time=1.923\n",
      "515 , Count:  160 , Train ID: 134 , Loss=0.031 , Time=1.988\n",
      "515 , Count:  161 , Train ID: 114 , Loss=0.031 , Time=2.137\n",
      "------------------------------------------------------------------\n",
      "Epoch: 515 to Epoch: 516------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "517 , Count:  1 , Train ID: 207 , Loss=0.031 , Time=2.110\n",
      "517 , Count:  2 , Train ID: 135 , Loss=0.031 , Time=1.937\n",
      "517 , Count:  3 , Train ID: 134 , Loss=0.031 , Time=2.014\n",
      "517 , Count:  4 , Train ID: 110 , Loss=0.031 , Time=1.912\n",
      "517 , Count:  5 , Train ID: 209 , Loss=0.031 , Time=2.065\n",
      "517 , Count:  6 , Train ID: 70 , Loss=0.031 , Time=2.056\n",
      "517 , Count:  7 , Train ID: 67 , Loss=0.031 , Time=1.992\n",
      "517 , Count:  8 , Train ID: 97 , Loss=0.031 , Time=1.972\n",
      "517 , Count:  9 , Train ID: 50 , Loss=0.031 , Time=2.039\n",
      "517 , Count:  10 , Train ID: 38 , Loss=0.031 , Time=1.982\n",
      "517 , Count:  11 , Train ID: 91 , Loss=0.031 , Time=1.971\n",
      "517 , Count:  12 , Train ID: 173 , Loss=0.031 , Time=2.007\n",
      "517 , Count:  13 , Train ID: 95 , Loss=0.031 , Time=2.051\n",
      "517 , Count:  14 , Train ID: 123 , Loss=0.031 , Time=1.944\n",
      "517 , Count:  15 , Train ID: 10 , Loss=0.031 , Time=2.090\n",
      "517 , Count:  16 , Train ID: 31 , Loss=0.031 , Time=1.950\n",
      "517 , Count:  17 , Train ID: 196 , Loss=0.031 , Time=1.939\n",
      "517 , Count:  18 , Train ID: 175 , Loss=0.031 , Time=1.895\n",
      "517 , Count:  19 , Train ID: 212 , Loss=0.031 , Time=2.058\n",
      "517 , Count:  20 , Train ID: 124 , Loss=0.031 , Time=2.104\n",
      "517 , Count:  21 , Train ID: 114 , Loss=0.031 , Time=2.011\n",
      "517 , Count:  22 , Train ID: 36 , Loss=0.031 , Time=2.042\n",
      "517 , Count:  23 , Train ID: 183 , Loss=0.031 , Time=1.926\n",
      "517 , Count:  24 , Train ID: 220 , Loss=0.031 , Time=1.905\n",
      "517 , Count:  25 , Train ID: 88 , Loss=0.031 , Time=1.927\n",
      "517 , Count:  26 , Train ID: 169 , Loss=0.031 , Time=1.966\n",
      "517 , Count:  27 , Train ID: 206 , Loss=0.030 , Time=1.950\n",
      "517 , Count:  28 , Train ID: 17 , Loss=0.030 , Time=1.949\n",
      "517 , Count:  29 , Train ID: 159 , Loss=0.030 , Time=2.017\n",
      "517 , Count:  30 , Train ID: 202 , Loss=0.031 , Time=2.963\n",
      "517 , Count:  31 , Train ID: 108 , Loss=0.030 , Time=2.033\n",
      "517 , Count:  32 , Train ID: 118 , Loss=0.030 , Time=1.956\n",
      "517 , Count:  33 , Train ID: 29 , Loss=0.030 , Time=1.947\n",
      "517 , Count:  34 , Train ID: 157 , Loss=0.030 , Time=1.955\n",
      "517 , Count:  35 , Train ID: 155 , Loss=0.030 , Time=2.027\n",
      "517 , Count:  36 , Train ID: 224 , Loss=0.030 , Time=1.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517 , Count:  37 , Train ID: 154 , Loss=0.030 , Time=2.053\n",
      "517 , Count:  38 , Train ID: 143 , Loss=0.030 , Time=1.946\n",
      "517 , Count:  39 , Train ID: 58 , Loss=0.030 , Time=2.015\n",
      "517 , Count:  40 , Train ID: 37 , Loss=0.030 , Time=2.020\n",
      "517 , Count:  41 , Train ID: 71 , Loss=0.030 , Time=1.968\n",
      "517 , Count:  42 , Train ID: 81 , Loss=0.030 , Time=2.021\n",
      "517 , Count:  43 , Train ID: 150 , Loss=0.030 , Time=2.026\n",
      "517 , Count:  44 , Train ID: 56 , Loss=0.030 , Time=2.947\n",
      "517 , Count:  45 , Train ID: 127 , Loss=0.030 , Time=1.946\n",
      "517 , Count:  46 , Train ID: 85 , Loss=0.030 , Time=2.103\n",
      "517 , Count:  47 , Train ID: 219 , Loss=0.030 , Time=2.129\n",
      "517 , Count:  48 , Train ID: 231 , Loss=0.030 , Time=2.976\n",
      "517 , Count:  49 , Train ID: 18 , Loss=0.030 , Time=2.019\n",
      "517 , Count:  50 , Train ID: 47 , Loss=0.030 , Time=2.039\n",
      "517 , Count:  51 , Train ID: 149 , Loss=0.030 , Time=1.987\n",
      "517 , Count:  52 , Train ID: 189 , Loss=0.030 , Time=1.990\n",
      "517 , Count:  53 , Train ID: 15 , Loss=0.030 , Time=2.954\n",
      "517 , Count:  54 , Train ID: 204 , Loss=0.030 , Time=1.877\n",
      "517 , Count:  55 , Train ID: 221 , Loss=0.030 , Time=1.990\n",
      "517 , Count:  56 , Train ID: 128 , Loss=0.030 , Time=1.958\n",
      "517 , Count:  57 , Train ID: 200 , Loss=0.030 , Time=2.050\n",
      "517 , Count:  58 , Train ID: 21 , Loss=0.030 , Time=2.129\n",
      "517 , Count:  59 , Train ID: 9 , Loss=0.030 , Time=3.063\n",
      "517 , Count:  60 , Train ID: 146 , Loss=0.030 , Time=1.962\n",
      "517 , Count:  61 , Train ID: 13 , Loss=0.030 , Time=1.957\n",
      "517 , Count:  62 , Train ID: 72 , Loss=0.030 , Time=2.068\n",
      "517 , Count:  63 , Train ID: 214 , Loss=0.030 , Time=1.997\n",
      "517 , Count:  64 , Train ID: 75 , Loss=0.030 , Time=1.968\n",
      "517 , Count:  65 , Train ID: 136 , Loss=0.030 , Time=1.917\n",
      "517 , Count:  66 , Train ID: 197 , Loss=0.030 , Time=2.013\n",
      "517 , Count:  67 , Train ID: 119 , Loss=0.030 , Time=2.076\n",
      "517 , Count:  68 , Train ID: 194 , Loss=0.030 , Time=2.037\n",
      "517 , Count:  69 , Train ID: 181 , Loss=0.030 , Time=2.087\n",
      "517 , Count:  70 , Train ID: 60 , Loss=0.030 , Time=1.944\n",
      "517 , Count:  71 , Train ID: 42 , Loss=0.030 , Time=1.983\n",
      "517 , Count:  72 , Train ID: 145 , Loss=0.030 , Time=2.024\n",
      "517 , Count:  73 , Train ID: 26 , Loss=0.030 , Time=1.938\n",
      "517 , Count:  74 , Train ID: 216 , Loss=0.030 , Time=3.071\n",
      "517 , Count:  75 , Train ID: 223 , Loss=0.030 , Time=1.996\n",
      "517 , Count:  76 , Train ID: 186 , Loss=0.030 , Time=1.971\n",
      "517 , Count:  77 , Train ID: 151 , Loss=0.030 , Time=2.002\n",
      "517 , Count:  78 , Train ID: 99 , Loss=0.030 , Time=1.965\n",
      "517 , Count:  79 , Train ID: 4 , Loss=0.030 , Time=2.070\n",
      "517 , Count:  80 , Train ID: 78 , Loss=0.030 , Time=1.994\n",
      "517 , Count:  81 , Train ID: 24 , Loss=0.030 , Time=2.083\n",
      "517 , Count:  82 , Train ID: 94 , Loss=0.030 , Time=2.025\n",
      "517 , Count:  83 , Train ID: 66 , Loss=0.030 , Time=1.964\n",
      "517 , Count:  84 , Train ID: 225 , Loss=0.030 , Time=3.024\n",
      "517 , Count:  85 , Train ID: 98 , Loss=0.030 , Time=2.018\n",
      "517 , Count:  86 , Train ID: 117 , Loss=0.030 , Time=1.932\n",
      "517 , Count:  87 , Train ID: 166 , Loss=0.030 , Time=2.034\n",
      "517 , Count:  88 , Train ID: 65 , Loss=0.030 , Time=1.951\n",
      "517 , Count:  89 , Train ID: 158 , Loss=0.030 , Time=2.026\n",
      "517 , Count:  90 , Train ID: 83 , Loss=0.030 , Time=1.990\n",
      "517 , Count:  91 , Train ID: 190 , Loss=0.030 , Time=2.070\n",
      "517 , Count:  92 , Train ID: 112 , Loss=0.030 , Time=2.038\n",
      "517 , Count:  93 , Train ID: 215 , Loss=0.030 , Time=2.086\n",
      "517 , Count:  94 , Train ID: 76 , Loss=0.030 , Time=2.016\n",
      "517 , Count:  95 , Train ID: 86 , Loss=0.030 , Time=1.917\n",
      "517 , Count:  96 , Train ID: 46 , Loss=0.030 , Time=2.025\n",
      "517 , Count:  97 , Train ID: 52 , Loss=0.030 , Time=2.086\n",
      "517 , Count:  98 , Train ID: 164 , Loss=0.030 , Time=2.070\n",
      "517 , Count:  99 , Train ID: 182 , Loss=0.030 , Time=2.076\n",
      "517 , Count:  100 , Train ID: 12 , Loss=0.030 , Time=1.991\n",
      "517 , Count:  101 , Train ID: 63 , Loss=0.030 , Time=2.020\n",
      "517 , Count:  102 , Train ID: 19 , Loss=0.030 , Time=3.056\n",
      "517 , Count:  103 , Train ID: 102 , Loss=0.030 , Time=2.077\n",
      "517 , Count:  104 , Train ID: 180 , Loss=0.030 , Time=2.094\n",
      "517 , Count:  105 , Train ID: 62 , Loss=0.030 , Time=2.016\n",
      "517 , Count:  106 , Train ID: 28 , Loss=0.030 , Time=3.042\n",
      "517 , Count:  107 , Train ID: 2 , Loss=0.030 , Time=2.031\n",
      "517 , Count:  108 , Train ID: 129 , Loss=0.030 , Time=2.019\n",
      "517 , Count:  109 , Train ID: 160 , Loss=0.030 , Time=1.945\n",
      "517 , Count:  110 , Train ID: 168 , Loss=0.030 , Time=2.089\n",
      "517 , Count:  111 , Train ID: 73 , Loss=0.030 , Time=1.914\n",
      "517 , Count:  112 , Train ID: 152 , Loss=0.030 , Time=2.024\n",
      "517 , Count:  113 , Train ID: 44 , Loss=0.030 , Time=2.033\n",
      "517 , Count:  114 , Train ID: 161 , Loss=0.031 , Time=2.039\n",
      "517 , Count:  115 , Train ID: 165 , Loss=0.030 , Time=2.079\n",
      "517 , Count:  116 , Train ID: 205 , Loss=0.030 , Time=1.927\n",
      "517 , Count:  117 , Train ID: 43 , Loss=0.030 , Time=2.891\n",
      "517 , Count:  118 , Train ID: 92 , Loss=0.030 , Time=1.939\n",
      "517 , Count:  119 , Train ID: 14 , Loss=0.030 , Time=1.927\n",
      "517 , Count:  120 , Train ID: 23 , Loss=0.030 , Time=1.967\n",
      "517 , Count:  121 , Train ID: 48 , Loss=0.030 , Time=1.927\n",
      "517 , Count:  122 , Train ID: 53 , Loss=0.030 , Time=1.963\n",
      "517 , Count:  123 , Train ID: 174 , Loss=0.030 , Time=1.946\n",
      "517 , Count:  124 , Train ID: 49 , Loss=0.030 , Time=1.969\n",
      "517 , Count:  125 , Train ID: 230 , Loss=0.030 , Time=1.937\n",
      "517 , Count:  126 , Train ID: 184 , Loss=0.030 , Time=1.944\n",
      "517 , Count:  127 , Train ID: 59 , Loss=0.030 , Time=1.998\n",
      "517 , Count:  128 , Train ID: 218 , Loss=0.030 , Time=1.970\n",
      "517 , Count:  129 , Train ID: 141 , Loss=0.030 , Time=2.027\n",
      "517 , Count:  130 , Train ID: 100 , Loss=0.030 , Time=1.896\n",
      "517 , Count:  131 , Train ID: 137 , Loss=0.030 , Time=1.990\n",
      "517 , Count:  132 , Train ID: 113 , Loss=0.030 , Time=1.989\n",
      "517 , Count:  133 , Train ID: 1 , Loss=0.030 , Time=2.006\n",
      "517 , Count:  134 , Train ID: 41 , Loss=0.030 , Time=1.951\n",
      "517 , Count:  135 , Train ID: 138 , Loss=0.030 , Time=2.046\n",
      "517 , Count:  136 , Train ID: 64 , Loss=0.030 , Time=1.928\n",
      "517 , Count:  137 , Train ID: 222 , Loss=0.030 , Time=2.965\n",
      "517 , Count:  138 , Train ID: 132 , Loss=0.030 , Time=2.039\n",
      "517 , Count:  139 , Train ID: 179 , Loss=0.030 , Time=2.058\n",
      "517 , Count:  140 , Train ID: 232 , Loss=0.030 , Time=3.085\n",
      "517 , Count:  141 , Train ID: 57 , Loss=0.030 , Time=2.054\n",
      "517 , Count:  142 , Train ID: 84 , Loss=0.030 , Time=2.047\n",
      "517 , Count:  143 , Train ID: 109 , Loss=0.030 , Time=1.988\n",
      "517 , Count:  144 , Train ID: 142 , Loss=0.030 , Time=2.106\n",
      "517 , Count:  145 , Train ID: 133 , Loss=0.030 , Time=1.955\n",
      "517 , Count:  146 , Train ID: 33 , Loss=0.030 , Time=2.040\n",
      "517 , Count:  147 , Train ID: 27 , Loss=0.030 , Time=2.015\n",
      "517 , Count:  148 , Train ID: 121 , Loss=0.030 , Time=1.971\n",
      "517 , Count:  149 , Train ID: 90 , Loss=0.030 , Time=2.032\n",
      "517 , Count:  150 , Train ID: 171 , Loss=0.030 , Time=1.952\n",
      "517 , Count:  151 , Train ID: 130 , Loss=0.030 , Time=1.977\n",
      "517 , Count:  152 , Train ID: 104 , Loss=0.030 , Time=1.920\n",
      "517 , Count:  153 , Train ID: 144 , Loss=0.030 , Time=1.961\n",
      "517 , Count:  154 , Train ID: 131 , Loss=0.030 , Time=2.061\n",
      "517 , Count:  155 , Train ID: 156 , Loss=0.030 , Time=1.945\n",
      "517 , Count:  156 , Train ID: 195 , Loss=0.030 , Time=1.934\n",
      "517 , Count:  157 , Train ID: 51 , Loss=0.030 , Time=2.010\n",
      "517 , Count:  158 , Train ID: 148 , Loss=0.030 , Time=1.971\n",
      "517 , Count:  159 , Train ID: 96 , Loss=0.030 , Time=1.981\n",
      "517 , Count:  160 , Train ID: 122 , Loss=0.030 , Time=1.962\n",
      "517 , Count:  161 , Train ID: 39 , Loss=0.030 , Time=2.021\n",
      "------------------------------------------------------------------\n",
      "Epoch: 517 to Epoch: 518------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "518 , Count:  1 , Train ID: 150 , Loss=0.030 , Time=2.056\n",
      "518 , Count:  2 , Train ID: 117 , Loss=0.030 , Time=2.026\n",
      "518 , Count:  3 , Train ID: 13 , Loss=0.030 , Time=2.079\n",
      "518 , Count:  4 , Train ID: 224 , Loss=0.030 , Time=2.086\n",
      "518 , Count:  5 , Train ID: 114 , Loss=0.030 , Time=1.988\n",
      "518 , Count:  6 , Train ID: 83 , Loss=0.030 , Time=1.978\n",
      "518 , Count:  7 , Train ID: 52 , Loss=0.030 , Time=2.075\n",
      "518 , Count:  8 , Train ID: 180 , Loss=0.029 , Time=2.095\n",
      "518 , Count:  9 , Train ID: 44 , Loss=0.029 , Time=2.110\n",
      "518 , Count:  10 , Train ID: 121 , Loss=0.029 , Time=1.950\n",
      "518 , Count:  11 , Train ID: 97 , Loss=0.030 , Time=2.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518 , Count:  12 , Train ID: 194 , Loss=0.029 , Time=3.047\n",
      "518 , Count:  13 , Train ID: 181 , Loss=0.029 , Time=1.947\n",
      "518 , Count:  14 , Train ID: 37 , Loss=0.029 , Time=1.957\n",
      "518 , Count:  15 , Train ID: 154 , Loss=0.029 , Time=2.047\n",
      "518 , Count:  16 , Train ID: 81 , Loss=0.029 , Time=1.952\n",
      "518 , Count:  17 , Train ID: 36 , Loss=0.029 , Time=2.000\n",
      "518 , Count:  18 , Train ID: 160 , Loss=0.029 , Time=1.908\n",
      "518 , Count:  19 , Train ID: 131 , Loss=0.029 , Time=1.942\n",
      "518 , Count:  20 , Train ID: 59 , Loss=0.029 , Time=2.069\n",
      "518 , Count:  21 , Train ID: 205 , Loss=0.029 , Time=2.011\n",
      "518 , Count:  22 , Train ID: 88 , Loss=0.029 , Time=2.018\n",
      "518 , Count:  23 , Train ID: 21 , Loss=0.029 , Time=2.044\n",
      "518 , Count:  24 , Train ID: 204 , Loss=0.029 , Time=1.923\n",
      "518 , Count:  25 , Train ID: 135 , Loss=0.029 , Time=2.011\n",
      "518 , Count:  26 , Train ID: 10 , Loss=0.029 , Time=1.929\n",
      "518 , Count:  27 , Train ID: 19 , Loss=0.030 , Time=1.929\n",
      "518 , Count:  28 , Train ID: 142 , Loss=0.030 , Time=1.929\n",
      "518 , Count:  29 , Train ID: 231 , Loss=0.030 , Time=3.037\n",
      "518 , Count:  30 , Train ID: 92 , Loss=0.029 , Time=2.042\n",
      "518 , Count:  31 , Train ID: 41 , Loss=0.030 , Time=2.084\n",
      "518 , Count:  32 , Train ID: 62 , Loss=0.030 , Time=1.919\n",
      "518 , Count:  33 , Train ID: 50 , Loss=0.030 , Time=1.951\n",
      "518 , Count:  34 , Train ID: 189 , Loss=0.030 , Time=1.908\n",
      "518 , Count:  35 , Train ID: 168 , Loss=0.030 , Time=1.944\n",
      "518 , Count:  36 , Train ID: 159 , Loss=0.030 , Time=1.956\n",
      "518 , Count:  37 , Train ID: 215 , Loss=0.030 , Time=2.054\n",
      "518 , Count:  38 , Train ID: 165 , Loss=0.030 , Time=1.946\n",
      "518 , Count:  39 , Train ID: 212 , Loss=0.030 , Time=2.062\n",
      "518 , Count:  40 , Train ID: 127 , Loss=0.030 , Time=2.048\n",
      "518 , Count:  41 , Train ID: 43 , Loss=0.030 , Time=1.951\n",
      "518 , Count:  42 , Train ID: 33 , Loss=0.030 , Time=2.064\n",
      "518 , Count:  43 , Train ID: 232 , Loss=0.030 , Time=2.043\n",
      "518 , Count:  44 , Train ID: 151 , Loss=0.030 , Time=2.087\n",
      "518 , Count:  45 , Train ID: 200 , Loss=0.030 , Time=2.949\n",
      "518 , Count:  46 , Train ID: 174 , Loss=0.030 , Time=1.937\n",
      "518 , Count:  47 , Train ID: 72 , Loss=0.030 , Time=1.969\n",
      "518 , Count:  48 , Train ID: 63 , Loss=0.030 , Time=2.063\n",
      "518 , Count:  49 , Train ID: 2 , Loss=0.030 , Time=2.004\n",
      "518 , Count:  50 , Train ID: 26 , Loss=0.030 , Time=3.147\n",
      "518 , Count:  51 , Train ID: 202 , Loss=0.029 , Time=1.927\n",
      "518 , Count:  52 , Train ID: 48 , Loss=0.029 , Time=2.071\n",
      "518 , Count:  53 , Train ID: 84 , Loss=0.030 , Time=2.102\n",
      "518 , Count:  54 , Train ID: 221 , Loss=0.029 , Time=2.013\n",
      "518 , Count:  55 , Train ID: 78 , Loss=0.029 , Time=2.023\n",
      "518 , Count:  56 , Train ID: 149 , Loss=0.029 , Time=2.084\n",
      "518 , Count:  57 , Train ID: 109 , Loss=0.029 , Time=2.054\n",
      "518 , Count:  58 , Train ID: 225 , Loss=0.029 , Time=1.984\n",
      "518 , Count:  59 , Train ID: 218 , Loss=0.029 , Time=2.955\n",
      "518 , Count:  60 , Train ID: 60 , Loss=0.029 , Time=1.991\n",
      "518 , Count:  61 , Train ID: 124 , Loss=0.029 , Time=2.045\n",
      "518 , Count:  62 , Train ID: 118 , Loss=0.029 , Time=1.977\n",
      "518 , Count:  63 , Train ID: 207 , Loss=0.029 , Time=2.080\n",
      "518 , Count:  64 , Train ID: 58 , Loss=0.029 , Time=1.954\n",
      "518 , Count:  65 , Train ID: 28 , Loss=0.029 , Time=1.965\n",
      "518 , Count:  66 , Train ID: 104 , Loss=0.029 , Time=2.004\n",
      "518 , Count:  67 , Train ID: 145 , Loss=0.029 , Time=1.957\n",
      "518 , Count:  68 , Train ID: 110 , Loss=0.029 , Time=2.034\n",
      "518 , Count:  69 , Train ID: 138 , Loss=0.029 , Time=2.102\n",
      "518 , Count:  70 , Train ID: 90 , Loss=0.029 , Time=2.041\n",
      "518 , Count:  71 , Train ID: 155 , Loss=0.029 , Time=1.953\n",
      "518 , Count:  72 , Train ID: 171 , Loss=0.029 , Time=1.983\n",
      "518 , Count:  73 , Train ID: 133 , Loss=0.030 , Time=1.970\n",
      "518 , Count:  74 , Train ID: 132 , Loss=0.030 , Time=2.096\n",
      "518 , Count:  75 , Train ID: 148 , Loss=0.030 , Time=2.066\n",
      "518 , Count:  76 , Train ID: 223 , Loss=0.029 , Time=2.108\n",
      "518 , Count:  77 , Train ID: 38 , Loss=0.030 , Time=1.936\n",
      "518 , Count:  78 , Train ID: 24 , Loss=0.030 , Time=1.981\n",
      "518 , Count:  79 , Train ID: 186 , Loss=0.030 , Time=3.051\n",
      "518 , Count:  80 , Train ID: 214 , Loss=0.030 , Time=2.043\n",
      "518 , Count:  81 , Train ID: 64 , Loss=0.030 , Time=2.064\n",
      "518 , Count:  82 , Train ID: 179 , Loss=0.029 , Time=2.055\n",
      "518 , Count:  83 , Train ID: 29 , Loss=0.029 , Time=2.036\n",
      "518 , Count:  84 , Train ID: 4 , Loss=0.029 , Time=2.018\n",
      "518 , Count:  85 , Train ID: 166 , Loss=0.029 , Time=2.088\n",
      "518 , Count:  86 , Train ID: 12 , Loss=0.029 , Time=2.002\n",
      "518 , Count:  87 , Train ID: 141 , Loss=0.029 , Time=2.027\n",
      "518 , Count:  88 , Train ID: 31 , Loss=0.029 , Time=2.052\n",
      "518 , Count:  89 , Train ID: 206 , Loss=0.030 , Time=2.124\n",
      "518 , Count:  90 , Train ID: 119 , Loss=0.030 , Time=2.015\n",
      "518 , Count:  91 , Train ID: 156 , Loss=0.030 , Time=2.050\n",
      "518 , Count:  92 , Train ID: 57 , Loss=0.030 , Time=1.910\n",
      "518 , Count:  93 , Train ID: 220 , Loss=0.030 , Time=2.009\n",
      "518 , Count:  94 , Train ID: 222 , Loss=0.030 , Time=1.952\n",
      "518 , Count:  95 , Train ID: 136 , Loss=0.030 , Time=2.069\n",
      "518 , Count:  96 , Train ID: 18 , Loss=0.030 , Time=1.954\n",
      "518 , Count:  97 , Train ID: 158 , Loss=0.030 , Time=1.928\n",
      "518 , Count:  98 , Train ID: 47 , Loss=0.030 , Time=2.090\n",
      "518 , Count:  99 , Train ID: 112 , Loss=0.030 , Time=1.991\n",
      "518 , Count:  100 , Train ID: 183 , Loss=0.030 , Time=1.965\n",
      "518 , Count:  101 , Train ID: 123 , Loss=0.030 , Time=2.039\n",
      "518 , Count:  102 , Train ID: 129 , Loss=0.030 , Time=2.109\n",
      "518 , Count:  103 , Train ID: 65 , Loss=0.030 , Time=2.089\n",
      "518 , Count:  104 , Train ID: 197 , Loss=0.030 , Time=1.929\n",
      "518 , Count:  105 , Train ID: 130 , Loss=0.030 , Time=2.135\n",
      "518 , Count:  106 , Train ID: 70 , Loss=0.030 , Time=2.081\n",
      "518 , Count:  107 , Train ID: 96 , Loss=0.030 , Time=2.090\n",
      "518 , Count:  108 , Train ID: 152 , Loss=0.030 , Time=2.046\n",
      "518 , Count:  109 , Train ID: 173 , Loss=0.030 , Time=2.014\n",
      "518 , Count:  110 , Train ID: 99 , Loss=0.030 , Time=2.038\n",
      "518 , Count:  111 , Train ID: 113 , Loss=0.030 , Time=2.008\n",
      "518 , Count:  112 , Train ID: 73 , Loss=0.029 , Time=1.933\n",
      "518 , Count:  113 , Train ID: 143 , Loss=0.029 , Time=2.113\n",
      "518 , Count:  114 , Train ID: 49 , Loss=0.030 , Time=3.243\n",
      "518 , Count:  115 , Train ID: 209 , Loss=0.030 , Time=2.008\n",
      "518 , Count:  116 , Train ID: 164 , Loss=0.030 , Time=1.950\n",
      "518 , Count:  117 , Train ID: 27 , Loss=0.030 , Time=1.985\n",
      "518 , Count:  118 , Train ID: 146 , Loss=0.030 , Time=1.998\n",
      "518 , Count:  119 , Train ID: 56 , Loss=0.030 , Time=1.915\n",
      "518 , Count:  120 , Train ID: 184 , Loss=0.030 , Time=2.045\n",
      "518 , Count:  121 , Train ID: 76 , Loss=0.030 , Time=2.011\n",
      "518 , Count:  122 , Train ID: 23 , Loss=0.030 , Time=1.954\n",
      "518 , Count:  123 , Train ID: 102 , Loss=0.030 , Time=2.091\n",
      "518 , Count:  124 , Train ID: 42 , Loss=0.030 , Time=2.018\n",
      "518 , Count:  125 , Train ID: 190 , Loss=0.030 , Time=2.021\n",
      "518 , Count:  126 , Train ID: 91 , Loss=0.030 , Time=1.995\n",
      "518 , Count:  127 , Train ID: 122 , Loss=0.030 , Time=2.062\n",
      "518 , Count:  128 , Train ID: 137 , Loss=0.030 , Time=2.107\n",
      "518 , Count:  129 , Train ID: 71 , Loss=0.030 , Time=2.085\n",
      "518 , Count:  130 , Train ID: 46 , Loss=0.030 , Time=2.031\n",
      "518 , Count:  131 , Train ID: 75 , Loss=0.030 , Time=2.072\n",
      "518 , Count:  132 , Train ID: 1 , Loss=0.030 , Time=2.042\n",
      "518 , Count:  133 , Train ID: 95 , Loss=0.030 , Time=2.054\n",
      "518 , Count:  134 , Train ID: 157 , Loss=0.030 , Time=2.041\n",
      "518 , Count:  135 , Train ID: 66 , Loss=0.030 , Time=1.965\n",
      "518 , Count:  136 , Train ID: 134 , Loss=0.030 , Time=2.077\n",
      "518 , Count:  137 , Train ID: 195 , Loss=0.029 , Time=2.026\n",
      "518 , Count:  138 , Train ID: 182 , Loss=0.029 , Time=2.031\n",
      "518 , Count:  139 , Train ID: 85 , Loss=0.029 , Time=1.926\n",
      "518 , Count:  140 , Train ID: 175 , Loss=0.029 , Time=2.035\n",
      "518 , Count:  141 , Train ID: 14 , Loss=0.029 , Time=2.056\n",
      "518 , Count:  142 , Train ID: 94 , Loss=0.029 , Time=1.914\n",
      "518 , Count:  143 , Train ID: 216 , Loss=0.029 , Time=2.071\n",
      "518 , Count:  144 , Train ID: 230 , Loss=0.029 , Time=1.971\n",
      "518 , Count:  145 , Train ID: 144 , Loss=0.029 , Time=2.058\n",
      "518 , Count:  146 , Train ID: 53 , Loss=0.029 , Time=2.051\n",
      "518 , Count:  147 , Train ID: 39 , Loss=0.029 , Time=2.093\n",
      "518 , Count:  148 , Train ID: 100 , Loss=0.029 , Time=2.031\n",
      "518 , Count:  149 , Train ID: 86 , Loss=0.030 , Time=1.968\n",
      "518 , Count:  150 , Train ID: 219 , Loss=0.029 , Time=1.989\n",
      "518 , Count:  151 , Train ID: 51 , Loss=0.029 , Time=2.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518 , Count:  152 , Train ID: 196 , Loss=0.029 , Time=1.921\n",
      "518 , Count:  153 , Train ID: 161 , Loss=0.029 , Time=2.011\n",
      "518 , Count:  154 , Train ID: 15 , Loss=0.029 , Time=2.050\n",
      "518 , Count:  155 , Train ID: 98 , Loss=0.029 , Time=2.033\n",
      "518 , Count:  156 , Train ID: 128 , Loss=0.030 , Time=1.959\n",
      "518 , Count:  157 , Train ID: 108 , Loss=0.030 , Time=2.028\n",
      "518 , Count:  158 , Train ID: 9 , Loss=0.030 , Time=2.011\n",
      "518 , Count:  159 , Train ID: 169 , Loss=0.030 , Time=1.985\n",
      "518 , Count:  160 , Train ID: 17 , Loss=0.030 , Time=1.988\n",
      "518 , Count:  161 , Train ID: 67 , Loss=0.030 , Time=2.063\n",
      "------------------------------------------------------------------\n",
      "Epoch: 518 to Epoch: 519------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "519 , Count:  1 , Train ID: 88 , Loss=0.030 , Time=2.019\n",
      "519 , Count:  2 , Train ID: 91 , Loss=0.030 , Time=1.973\n",
      "519 , Count:  3 , Train ID: 194 , Loss=0.029 , Time=2.069\n",
      "519 , Count:  4 , Train ID: 78 , Loss=0.029 , Time=1.989\n",
      "519 , Count:  5 , Train ID: 21 , Loss=0.029 , Time=1.995\n",
      "519 , Count:  6 , Train ID: 129 , Loss=0.029 , Time=1.978\n",
      "519 , Count:  7 , Train ID: 179 , Loss=0.030 , Time=3.020\n",
      "519 , Count:  8 , Train ID: 1 , Loss=0.030 , Time=2.023\n",
      "519 , Count:  9 , Train ID: 212 , Loss=0.030 , Time=2.032\n",
      "519 , Count:  10 , Train ID: 151 , Loss=0.030 , Time=2.058\n",
      "519 , Count:  11 , Train ID: 144 , Loss=0.030 , Time=2.043\n",
      "519 , Count:  12 , Train ID: 67 , Loss=0.030 , Time=1.972\n",
      "519 , Count:  13 , Train ID: 71 , Loss=0.030 , Time=2.007\n",
      "519 , Count:  14 , Train ID: 66 , Loss=0.030 , Time=1.951\n",
      "519 , Count:  15 , Train ID: 149 , Loss=0.030 , Time=1.969\n",
      "519 , Count:  16 , Train ID: 94 , Loss=0.030 , Time=1.919\n",
      "519 , Count:  17 , Train ID: 102 , Loss=0.030 , Time=1.988\n",
      "519 , Count:  18 , Train ID: 98 , Loss=0.030 , Time=2.043\n",
      "519 , Count:  19 , Train ID: 186 , Loss=0.030 , Time=1.953\n",
      "519 , Count:  20 , Train ID: 85 , Loss=0.030 , Time=2.097\n",
      "519 , Count:  21 , Train ID: 143 , Loss=0.030 , Time=1.938\n",
      "519 , Count:  22 , Train ID: 219 , Loss=0.030 , Time=2.110\n",
      "519 , Count:  23 , Train ID: 148 , Loss=0.030 , Time=1.929\n",
      "519 , Count:  24 , Train ID: 112 , Loss=0.030 , Time=2.021\n",
      "519 , Count:  25 , Train ID: 175 , Loss=0.030 , Time=1.994\n",
      "519 , Count:  26 , Train ID: 90 , Loss=0.030 , Time=1.979\n",
      "519 , Count:  27 , Train ID: 223 , Loss=0.030 , Time=3.018\n",
      "519 , Count:  28 , Train ID: 26 , Loss=0.030 , Time=2.024\n",
      "519 , Count:  29 , Train ID: 161 , Loss=0.030 , Time=1.961\n",
      "519 , Count:  30 , Train ID: 51 , Loss=0.030 , Time=3.056\n",
      "519 , Count:  31 , Train ID: 13 , Loss=0.030 , Time=1.897\n",
      "519 , Count:  32 , Train ID: 72 , Loss=0.030 , Time=1.939\n",
      "519 , Count:  33 , Train ID: 123 , Loss=0.030 , Time=2.003\n",
      "519 , Count:  34 , Train ID: 92 , Loss=0.030 , Time=2.101\n",
      "519 , Count:  35 , Train ID: 127 , Loss=0.030 , Time=1.992\n",
      "519 , Count:  36 , Train ID: 128 , Loss=0.030 , Time=1.972\n",
      "519 , Count:  37 , Train ID: 50 , Loss=0.030 , Time=1.984\n",
      "519 , Count:  38 , Train ID: 2 , Loss=0.030 , Time=1.964\n",
      "519 , Count:  39 , Train ID: 133 , Loss=0.030 , Time=2.046\n",
      "519 , Count:  40 , Train ID: 135 , Loss=0.030 , Time=2.052\n",
      "519 , Count:  41 , Train ID: 130 , Loss=0.030 , Time=1.963\n",
      "519 , Count:  42 , Train ID: 142 , Loss=0.030 , Time=2.050\n",
      "519 , Count:  43 , Train ID: 14 , Loss=0.030 , Time=1.930\n",
      "519 , Count:  44 , Train ID: 38 , Loss=0.030 , Time=2.116\n",
      "519 , Count:  45 , Train ID: 73 , Loss=0.030 , Time=2.047\n",
      "519 , Count:  46 , Train ID: 196 , Loss=0.030 , Time=1.940\n",
      "519 , Count:  47 , Train ID: 109 , Loss=0.030 , Time=1.976\n",
      "519 , Count:  48 , Train ID: 104 , Loss=0.030 , Time=2.005\n",
      "519 , Count:  49 , Train ID: 110 , Loss=0.030 , Time=2.038\n",
      "519 , Count:  50 , Train ID: 138 , Loss=0.030 , Time=2.050\n",
      "519 , Count:  51 , Train ID: 207 , Loss=0.030 , Time=2.049\n",
      "519 , Count:  52 , Train ID: 57 , Loss=0.030 , Time=1.944\n",
      "519 , Count:  53 , Train ID: 122 , Loss=0.030 , Time=2.013\n",
      "519 , Count:  54 , Train ID: 114 , Loss=0.030 , Time=2.003\n",
      "519 , Count:  55 , Train ID: 157 , Loss=0.030 , Time=1.914\n",
      "519 , Count:  56 , Train ID: 154 , Loss=0.030 , Time=2.006\n",
      "519 , Count:  57 , Train ID: 37 , Loss=0.030 , Time=2.020\n",
      "519 , Count:  58 , Train ID: 18 , Loss=0.030 , Time=1.981\n",
      "519 , Count:  59 , Train ID: 214 , Loss=0.030 , Time=2.895\n",
      "519 , Count:  60 , Train ID: 46 , Loss=0.030 , Time=2.038\n",
      "519 , Count:  61 , Train ID: 24 , Loss=0.030 , Time=2.064\n",
      "519 , Count:  62 , Train ID: 4 , Loss=0.030 , Time=1.986\n",
      "519 , Count:  63 , Train ID: 202 , Loss=0.030 , Time=1.952\n",
      "519 , Count:  64 , Train ID: 225 , Loss=0.030 , Time=2.110\n",
      "519 , Count:  65 , Train ID: 65 , Loss=0.030 , Time=2.033\n",
      "519 , Count:  66 , Train ID: 174 , Loss=0.030 , Time=1.977\n",
      "519 , Count:  67 , Train ID: 156 , Loss=0.030 , Time=2.099\n",
      "519 , Count:  68 , Train ID: 42 , Loss=0.030 , Time=1.961\n",
      "519 , Count:  69 , Train ID: 86 , Loss=0.030 , Time=2.044\n",
      "519 , Count:  70 , Train ID: 165 , Loss=0.030 , Time=2.097\n",
      "519 , Count:  71 , Train ID: 75 , Loss=0.030 , Time=2.013\n",
      "519 , Count:  72 , Train ID: 215 , Loss=0.030 , Time=2.038\n",
      "519 , Count:  73 , Train ID: 159 , Loss=0.030 , Time=2.029\n",
      "519 , Count:  74 , Train ID: 134 , Loss=0.030 , Time=2.037\n",
      "519 , Count:  75 , Train ID: 155 , Loss=0.030 , Time=2.059\n",
      "519 , Count:  76 , Train ID: 146 , Loss=0.030 , Time=1.972\n",
      "519 , Count:  77 , Train ID: 131 , Loss=0.030 , Time=2.160\n",
      "519 , Count:  78 , Train ID: 52 , Loss=0.030 , Time=2.072\n",
      "519 , Count:  79 , Train ID: 95 , Loss=0.030 , Time=2.014\n",
      "519 , Count:  80 , Train ID: 48 , Loss=0.030 , Time=2.096\n",
      "519 , Count:  81 , Train ID: 39 , Loss=0.030 , Time=1.994\n",
      "519 , Count:  82 , Train ID: 137 , Loss=0.030 , Time=1.977\n",
      "519 , Count:  83 , Train ID: 184 , Loss=0.030 , Time=2.099\n",
      "519 , Count:  84 , Train ID: 168 , Loss=0.030 , Time=2.007\n",
      "519 , Count:  85 , Train ID: 28 , Loss=0.030 , Time=1.917\n",
      "519 , Count:  86 , Train ID: 59 , Loss=0.030 , Time=2.085\n",
      "519 , Count:  87 , Train ID: 84 , Loss=0.029 , Time=2.017\n",
      "519 , Count:  88 , Train ID: 152 , Loss=0.030 , Time=2.106\n",
      "519 , Count:  89 , Train ID: 160 , Loss=0.029 , Time=2.040\n",
      "519 , Count:  90 , Train ID: 108 , Loss=0.029 , Time=2.041\n",
      "519 , Count:  91 , Train ID: 23 , Loss=0.029 , Time=1.980\n",
      "519 , Count:  92 , Train ID: 164 , Loss=0.029 , Time=2.094\n",
      "519 , Count:  93 , Train ID: 224 , Loss=0.029 , Time=1.974\n",
      "519 , Count:  94 , Train ID: 43 , Loss=0.029 , Time=2.018\n",
      "519 , Count:  95 , Train ID: 169 , Loss=0.029 , Time=2.047\n",
      "519 , Count:  96 , Train ID: 222 , Loss=0.030 , Time=2.081\n",
      "519 , Count:  97 , Train ID: 15 , Loss=0.030 , Time=2.018\n",
      "519 , Count:  98 , Train ID: 12 , Loss=0.030 , Time=2.085\n",
      "519 , Count:  99 , Train ID: 220 , Loss=0.030 , Time=1.964\n",
      "519 , Count:  100 , Train ID: 197 , Loss=0.030 , Time=1.915\n",
      "519 , Count:  101 , Train ID: 19 , Loss=0.029 , Time=1.955\n",
      "519 , Count:  102 , Train ID: 56 , Loss=0.029 , Time=2.104\n",
      "519 , Count:  103 , Train ID: 150 , Loss=0.029 , Time=2.079\n",
      "519 , Count:  104 , Train ID: 182 , Loss=0.029 , Time=2.046\n",
      "519 , Count:  105 , Train ID: 41 , Loss=0.029 , Time=2.024\n",
      "519 , Count:  106 , Train ID: 99 , Loss=0.029 , Time=1.947\n",
      "519 , Count:  107 , Train ID: 190 , Loss=0.029 , Time=3.011\n",
      "519 , Count:  108 , Train ID: 117 , Loss=0.029 , Time=2.069\n",
      "519 , Count:  109 , Train ID: 36 , Loss=0.029 , Time=2.168\n",
      "519 , Count:  110 , Train ID: 232 , Loss=0.029 , Time=1.986\n",
      "519 , Count:  111 , Train ID: 230 , Loss=0.030 , Time=1.996\n",
      "519 , Count:  112 , Train ID: 200 , Loss=0.030 , Time=1.938\n",
      "519 , Count:  113 , Train ID: 62 , Loss=0.030 , Time=2.093\n",
      "519 , Count:  114 , Train ID: 204 , Loss=0.030 , Time=2.093\n",
      "519 , Count:  115 , Train ID: 76 , Loss=0.029 , Time=2.036\n",
      "519 , Count:  116 , Train ID: 44 , Loss=0.029 , Time=2.107\n",
      "519 , Count:  117 , Train ID: 173 , Loss=0.030 , Time=2.133\n",
      "519 , Count:  118 , Train ID: 183 , Loss=0.030 , Time=2.063\n",
      "519 , Count:  119 , Train ID: 118 , Loss=0.030 , Time=2.098\n",
      "519 , Count:  120 , Train ID: 121 , Loss=0.030 , Time=1.953\n",
      "519 , Count:  121 , Train ID: 216 , Loss=0.030 , Time=2.001\n",
      "519 , Count:  122 , Train ID: 97 , Loss=0.030 , Time=2.036\n",
      "519 , Count:  123 , Train ID: 9 , Loss=0.030 , Time=2.074\n",
      "519 , Count:  124 , Train ID: 180 , Loss=0.030 , Time=2.032\n",
      "519 , Count:  125 , Train ID: 166 , Loss=0.030 , Time=2.070\n",
      "519 , Count:  126 , Train ID: 124 , Loss=0.030 , Time=1.951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519 , Count:  127 , Train ID: 221 , Loss=0.030 , Time=1.982\n",
      "519 , Count:  128 , Train ID: 49 , Loss=0.030 , Time=1.985\n",
      "519 , Count:  129 , Train ID: 158 , Loss=0.030 , Time=1.899\n",
      "519 , Count:  130 , Train ID: 27 , Loss=0.030 , Time=2.029\n",
      "519 , Count:  131 , Train ID: 60 , Loss=0.030 , Time=1.985\n",
      "519 , Count:  132 , Train ID: 31 , Loss=0.030 , Time=1.975\n",
      "519 , Count:  133 , Train ID: 70 , Loss=0.030 , Time=1.991\n",
      "519 , Count:  134 , Train ID: 195 , Loss=0.030 , Time=1.954\n",
      "519 , Count:  135 , Train ID: 29 , Loss=0.030 , Time=1.973\n",
      "519 , Count:  136 , Train ID: 181 , Loss=0.030 , Time=1.964\n",
      "519 , Count:  137 , Train ID: 231 , Loss=0.030 , Time=2.070\n",
      "519 , Count:  138 , Train ID: 10 , Loss=0.030 , Time=2.109\n",
      "519 , Count:  139 , Train ID: 47 , Loss=0.030 , Time=1.956\n",
      "519 , Count:  140 , Train ID: 136 , Loss=0.030 , Time=2.085\n",
      "519 , Count:  141 , Train ID: 171 , Loss=0.030 , Time=1.973\n",
      "519 , Count:  142 , Train ID: 96 , Loss=0.030 , Time=2.091\n",
      "519 , Count:  143 , Train ID: 64 , Loss=0.030 , Time=2.041\n",
      "519 , Count:  144 , Train ID: 81 , Loss=0.030 , Time=2.033\n",
      "519 , Count:  145 , Train ID: 189 , Loss=0.030 , Time=2.099\n",
      "519 , Count:  146 , Train ID: 17 , Loss=0.030 , Time=2.115\n",
      "519 , Count:  147 , Train ID: 145 , Loss=0.030 , Time=2.083\n",
      "519 , Count:  148 , Train ID: 53 , Loss=0.030 , Time=1.966\n",
      "519 , Count:  149 , Train ID: 58 , Loss=0.030 , Time=2.034\n",
      "519 , Count:  150 , Train ID: 113 , Loss=0.030 , Time=2.055\n",
      "519 , Count:  151 , Train ID: 132 , Loss=0.030 , Time=2.056\n",
      "519 , Count:  152 , Train ID: 206 , Loss=0.030 , Time=2.062\n",
      "519 , Count:  153 , Train ID: 205 , Loss=0.030 , Time=2.080\n",
      "519 , Count:  154 , Train ID: 119 , Loss=0.030 , Time=1.999\n",
      "519 , Count:  155 , Train ID: 33 , Loss=0.030 , Time=2.098\n",
      "519 , Count:  156 , Train ID: 218 , Loss=0.030 , Time=2.064\n",
      "519 , Count:  157 , Train ID: 63 , Loss=0.030 , Time=2.058\n",
      "519 , Count:  158 , Train ID: 83 , Loss=0.030 , Time=1.938\n",
      "519 , Count:  159 , Train ID: 209 , Loss=0.030 , Time=1.958\n",
      "519 , Count:  160 , Train ID: 100 , Loss=0.030 , Time=2.095\n",
      "519 , Count:  161 , Train ID: 141 , Loss=0.030 , Time=2.142\n",
      "------------------------------------------------------------------\n",
      "Epoch: 519 to Epoch: 520------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "520 , Count:  1 , Train ID: 100 , Loss=0.030 , Time=2.057\n",
      "520 , Count:  2 , Train ID: 17 , Loss=0.030 , Time=2.114\n",
      "520 , Count:  3 , Train ID: 27 , Loss=0.030 , Time=1.939\n",
      "520 , Count:  4 , Train ID: 155 , Loss=0.030 , Time=1.983\n",
      "520 , Count:  5 , Train ID: 152 , Loss=0.030 , Time=2.046\n",
      "520 , Count:  6 , Train ID: 57 , Loss=0.030 , Time=1.946\n",
      "520 , Count:  7 , Train ID: 232 , Loss=0.030 , Time=2.111\n",
      "520 , Count:  8 , Train ID: 48 , Loss=0.030 , Time=1.895\n",
      "520 , Count:  9 , Train ID: 62 , Loss=0.030 , Time=1.982\n",
      "520 , Count:  10 , Train ID: 141 , Loss=0.030 , Time=2.083\n",
      "520 , Count:  11 , Train ID: 148 , Loss=0.030 , Time=1.965\n",
      "520 , Count:  12 , Train ID: 39 , Loss=0.030 , Time=2.050\n",
      "520 , Count:  13 , Train ID: 46 , Loss=0.030 , Time=1.967\n",
      "520 , Count:  14 , Train ID: 202 , Loss=0.030 , Time=2.029\n",
      "520 , Count:  15 , Train ID: 50 , Loss=0.030 , Time=2.048\n",
      "520 , Count:  16 , Train ID: 19 , Loss=0.030 , Time=2.044\n",
      "520 , Count:  17 , Train ID: 183 , Loss=0.030 , Time=2.018\n",
      "520 , Count:  18 , Train ID: 144 , Loss=0.030 , Time=1.964\n",
      "520 , Count:  19 , Train ID: 207 , Loss=0.030 , Time=2.094\n",
      "520 , Count:  20 , Train ID: 138 , Loss=0.030 , Time=2.079\n",
      "520 , Count:  21 , Train ID: 231 , Loss=0.030 , Time=2.079\n",
      "520 , Count:  22 , Train ID: 53 , Loss=0.030 , Time=1.949\n",
      "520 , Count:  23 , Train ID: 118 , Loss=0.030 , Time=2.031\n",
      "520 , Count:  24 , Train ID: 190 , Loss=0.030 , Time=2.133\n",
      "520 , Count:  25 , Train ID: 38 , Loss=0.030 , Time=1.947\n",
      "520 , Count:  26 , Train ID: 223 , Loss=0.030 , Time=2.025\n",
      "520 , Count:  27 , Train ID: 76 , Loss=0.030 , Time=2.091\n",
      "520 , Count:  28 , Train ID: 173 , Loss=0.030 , Time=2.081\n",
      "520 , Count:  29 , Train ID: 149 , Loss=0.030 , Time=2.039\n",
      "520 , Count:  30 , Train ID: 99 , Loss=0.030 , Time=1.953\n",
      "520 , Count:  31 , Train ID: 70 , Loss=0.030 , Time=2.092\n",
      "520 , Count:  32 , Train ID: 214 , Loss=0.030 , Time=2.056\n",
      "520 , Count:  33 , Train ID: 9 , Loss=0.030 , Time=2.001\n",
      "520 , Count:  34 , Train ID: 209 , Loss=0.030 , Time=2.063\n",
      "520 , Count:  35 , Train ID: 14 , Loss=0.030 , Time=2.056\n",
      "520 , Count:  36 , Train ID: 194 , Loss=0.030 , Time=2.066\n",
      "520 , Count:  37 , Train ID: 174 , Loss=0.030 , Time=2.016\n",
      "520 , Count:  38 , Train ID: 88 , Loss=0.030 , Time=2.083\n",
      "520 , Count:  39 , Train ID: 49 , Loss=0.030 , Time=1.948\n",
      "520 , Count:  40 , Train ID: 131 , Loss=0.030 , Time=2.098\n",
      "520 , Count:  41 , Train ID: 220 , Loss=0.030 , Time=1.950\n",
      "520 , Count:  42 , Train ID: 81 , Loss=0.030 , Time=2.038\n",
      "520 , Count:  43 , Train ID: 212 , Loss=0.030 , Time=2.060\n",
      "520 , Count:  44 , Train ID: 47 , Loss=0.030 , Time=2.118\n",
      "520 , Count:  45 , Train ID: 75 , Loss=0.030 , Time=2.117\n",
      "520 , Count:  46 , Train ID: 122 , Loss=0.030 , Time=1.989\n",
      "520 , Count:  47 , Train ID: 158 , Loss=0.030 , Time=2.040\n",
      "520 , Count:  48 , Train ID: 108 , Loss=0.030 , Time=2.028\n",
      "520 , Count:  49 , Train ID: 133 , Loss=0.030 , Time=2.081\n",
      "520 , Count:  50 , Train ID: 117 , Loss=0.030 , Time=2.037\n",
      "520 , Count:  51 , Train ID: 56 , Loss=0.030 , Time=2.135\n",
      "520 , Count:  52 , Train ID: 104 , Loss=0.030 , Time=2.161\n",
      "520 , Count:  53 , Train ID: 72 , Loss=0.030 , Time=2.105\n",
      "520 , Count:  54 , Train ID: 42 , Loss=0.030 , Time=1.977\n",
      "520 , Count:  55 , Train ID: 151 , Loss=0.030 , Time=2.077\n",
      "520 , Count:  56 , Train ID: 33 , Loss=0.030 , Time=1.975\n",
      "520 , Count:  57 , Train ID: 136 , Loss=0.030 , Time=1.929\n",
      "520 , Count:  58 , Train ID: 114 , Loss=0.030 , Time=1.980\n",
      "520 , Count:  59 , Train ID: 196 , Loss=0.030 , Time=1.972\n",
      "520 , Count:  60 , Train ID: 169 , Loss=0.030 , Time=2.080\n",
      "520 , Count:  61 , Train ID: 66 , Loss=0.030 , Time=1.943\n",
      "520 , Count:  62 , Train ID: 189 , Loss=0.030 , Time=2.115\n",
      "520 , Count:  63 , Train ID: 218 , Loss=0.030 , Time=2.027\n",
      "520 , Count:  64 , Train ID: 219 , Loss=0.030 , Time=1.977\n",
      "520 , Count:  65 , Train ID: 63 , Loss=0.030 , Time=1.933\n",
      "520 , Count:  66 , Train ID: 21 , Loss=0.030 , Time=2.037\n",
      "520 , Count:  67 , Train ID: 119 , Loss=0.030 , Time=2.016\n",
      "520 , Count:  68 , Train ID: 29 , Loss=0.030 , Time=1.975\n",
      "520 , Count:  69 , Train ID: 36 , Loss=0.030 , Time=2.114\n",
      "520 , Count:  70 , Train ID: 204 , Loss=0.030 , Time=1.977\n",
      "520 , Count:  71 , Train ID: 10 , Loss=0.030 , Time=2.141\n",
      "520 , Count:  72 , Train ID: 165 , Loss=0.030 , Time=2.006\n",
      "520 , Count:  73 , Train ID: 130 , Loss=0.030 , Time=1.964\n",
      "520 , Count:  74 , Train ID: 44 , Loss=0.030 , Time=2.070\n",
      "520 , Count:  75 , Train ID: 73 , Loss=0.030 , Time=2.043\n",
      "520 , Count:  76 , Train ID: 121 , Loss=0.030 , Time=1.970\n",
      "520 , Count:  77 , Train ID: 1 , Loss=0.030 , Time=1.958\n",
      "520 , Count:  78 , Train ID: 65 , Loss=0.030 , Time=2.068\n",
      "520 , Count:  79 , Train ID: 94 , Loss=0.030 , Time=2.095\n",
      "520 , Count:  80 , Train ID: 26 , Loss=0.030 , Time=2.022\n",
      "520 , Count:  81 , Train ID: 24 , Loss=0.030 , Time=2.019\n",
      "520 , Count:  82 , Train ID: 18 , Loss=0.030 , Time=2.169\n",
      "520 , Count:  83 , Train ID: 142 , Loss=0.030 , Time=2.097\n",
      "520 , Count:  84 , Train ID: 123 , Loss=0.030 , Time=2.084\n",
      "520 , Count:  85 , Train ID: 161 , Loss=0.030 , Time=2.029\n",
      "520 , Count:  86 , Train ID: 186 , Loss=0.030 , Time=2.153\n",
      "520 , Count:  87 , Train ID: 146 , Loss=0.030 , Time=2.029\n",
      "520 , Count:  88 , Train ID: 184 , Loss=0.030 , Time=1.901\n",
      "520 , Count:  89 , Train ID: 84 , Loss=0.030 , Time=1.958\n",
      "520 , Count:  90 , Train ID: 135 , Loss=0.030 , Time=1.994\n",
      "520 , Count:  91 , Train ID: 112 , Loss=0.030 , Time=2.119\n",
      "520 , Count:  92 , Train ID: 224 , Loss=0.030 , Time=2.004\n",
      "520 , Count:  93 , Train ID: 197 , Loss=0.030 , Time=2.016\n",
      "520 , Count:  94 , Train ID: 215 , Loss=0.030 , Time=1.989\n",
      "520 , Count:  95 , Train ID: 168 , Loss=0.030 , Time=1.957\n",
      "520 , Count:  96 , Train ID: 171 , Loss=0.030 , Time=2.041\n",
      "520 , Count:  97 , Train ID: 216 , Loss=0.030 , Time=1.917\n",
      "520 , Count:  98 , Train ID: 86 , Loss=0.030 , Time=2.125\n",
      "520 , Count:  99 , Train ID: 182 , Loss=0.030 , Time=2.008\n",
      "520 , Count:  100 , Train ID: 221 , Loss=0.030 , Time=1.974\n",
      "520 , Count:  101 , Train ID: 164 , Loss=0.030 , Time=2.175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520 , Count:  102 , Train ID: 137 , Loss=0.030 , Time=1.997\n",
      "520 , Count:  103 , Train ID: 78 , Loss=0.030 , Time=2.074\n",
      "520 , Count:  104 , Train ID: 225 , Loss=0.030 , Time=2.121\n",
      "520 , Count:  105 , Train ID: 15 , Loss=0.030 , Time=1.997\n",
      "520 , Count:  106 , Train ID: 41 , Loss=0.030 , Time=2.147\n",
      "520 , Count:  107 , Train ID: 113 , Loss=0.030 , Time=2.084\n",
      "520 , Count:  108 , Train ID: 2 , Loss=0.030 , Time=2.169\n",
      "520 , Count:  109 , Train ID: 37 , Loss=0.030 , Time=2.116\n",
      "520 , Count:  110 , Train ID: 157 , Loss=0.030 , Time=1.964\n",
      "520 , Count:  111 , Train ID: 154 , Loss=0.031 , Time=2.120\n",
      "520 , Count:  112 , Train ID: 132 , Loss=0.031 , Time=1.951\n",
      "520 , Count:  113 , Train ID: 31 , Loss=0.031 , Time=2.011\n",
      "520 , Count:  114 , Train ID: 92 , Loss=0.031 , Time=1.979\n",
      "520 , Count:  115 , Train ID: 124 , Loss=0.031 , Time=1.971\n",
      "520 , Count:  116 , Train ID: 52 , Loss=0.030 , Time=2.018\n",
      "520 , Count:  117 , Train ID: 64 , Loss=0.030 , Time=1.960\n",
      "520 , Count:  118 , Train ID: 91 , Loss=0.030 , Time=2.009\n",
      "520 , Count:  119 , Train ID: 143 , Loss=0.030 , Time=1.994\n",
      "520 , Count:  120 , Train ID: 160 , Loss=0.030 , Time=2.025\n",
      "520 , Count:  121 , Train ID: 128 , Loss=0.030 , Time=2.115\n",
      "520 , Count:  122 , Train ID: 200 , Loss=0.030 , Time=2.066\n",
      "520 , Count:  123 , Train ID: 109 , Loss=0.030 , Time=1.965\n",
      "520 , Count:  124 , Train ID: 59 , Loss=0.030 , Time=2.013\n",
      "520 , Count:  125 , Train ID: 97 , Loss=0.030 , Time=1.963\n",
      "520 , Count:  126 , Train ID: 67 , Loss=0.030 , Time=2.012\n",
      "520 , Count:  127 , Train ID: 102 , Loss=0.030 , Time=1.951\n",
      "520 , Count:  128 , Train ID: 127 , Loss=0.030 , Time=2.043\n",
      "520 , Count:  129 , Train ID: 58 , Loss=0.030 , Time=2.031\n",
      "520 , Count:  130 , Train ID: 206 , Loss=0.030 , Time=2.141\n",
      "520 , Count:  131 , Train ID: 166 , Loss=0.030 , Time=2.003\n",
      "520 , Count:  132 , Train ID: 4 , Loss=0.030 , Time=2.021\n",
      "520 , Count:  133 , Train ID: 145 , Loss=0.030 , Time=2.018\n",
      "520 , Count:  134 , Train ID: 230 , Loss=0.030 , Time=2.221\n",
      "520 , Count:  135 , Train ID: 175 , Loss=0.030 , Time=2.036\n",
      "520 , Count:  136 , Train ID: 95 , Loss=0.030 , Time=2.174\n",
      "520 , Count:  137 , Train ID: 195 , Loss=0.030 , Time=3.181\n",
      "520 , Count:  138 , Train ID: 12 , Loss=0.030 , Time=2.058\n",
      "520 , Count:  139 , Train ID: 150 , Loss=0.030 , Time=1.955\n",
      "520 , Count:  140 , Train ID: 222 , Loss=0.029 , Time=1.978\n",
      "520 , Count:  141 , Train ID: 159 , Loss=0.029 , Time=2.076\n",
      "520 , Count:  142 , Train ID: 85 , Loss=0.029 , Time=2.132\n",
      "520 , Count:  143 , Train ID: 110 , Loss=0.029 , Time=2.123\n",
      "520 , Count:  144 , Train ID: 71 , Loss=0.029 , Time=1.978\n",
      "520 , Count:  145 , Train ID: 181 , Loss=0.029 , Time=1.908\n",
      "520 , Count:  146 , Train ID: 96 , Loss=0.029 , Time=2.208\n",
      "520 , Count:  147 , Train ID: 83 , Loss=0.029 , Time=2.085\n",
      "520 , Count:  148 , Train ID: 90 , Loss=0.029 , Time=2.126\n",
      "520 , Count:  149 , Train ID: 98 , Loss=0.029 , Time=2.010\n",
      "520 , Count:  150 , Train ID: 23 , Loss=0.029 , Time=2.011\n",
      "520 , Count:  151 , Train ID: 205 , Loss=0.029 , Time=2.059\n",
      "520 , Count:  152 , Train ID: 156 , Loss=0.029 , Time=1.995\n",
      "520 , Count:  153 , Train ID: 13 , Loss=0.029 , Time=2.039\n",
      "520 , Count:  154 , Train ID: 180 , Loss=0.029 , Time=1.961\n",
      "520 , Count:  155 , Train ID: 28 , Loss=0.029 , Time=1.972\n",
      "520 , Count:  156 , Train ID: 60 , Loss=0.029 , Time=2.067\n",
      "520 , Count:  157 , Train ID: 43 , Loss=0.029 , Time=2.001\n",
      "520 , Count:  158 , Train ID: 129 , Loss=0.029 , Time=1.938\n",
      "520 , Count:  159 , Train ID: 134 , Loss=0.029 , Time=2.087\n",
      "520 , Count:  160 , Train ID: 51 , Loss=0.029 , Time=1.987\n",
      "520 , Count:  161 , Train ID: 179 , Loss=0.029 , Time=2.054\n",
      "------------------------------------------------------------------\n",
      "Epoch: 520 to Epoch: 521------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Training Started------------------------------------------------------------------\\n------------------------------------------------------------------\\n------------------------------------------------------------------')        \n",
    "np.random.seed(10)\n",
    "lastepoch = 0\n",
    "for folder in allfolders:\n",
    "    lastepoch = np.maximum(lastepoch, int(folder[-4:]))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for epoch in range(lastepoch, 520):\n",
    "    if os.path.isdir(result_dir + '%04d' % epoch):\n",
    "        continue\n",
    "    cnt = 0\n",
    "    if epoch > 2000:\n",
    "        learning_rate = 1e-5\n",
    "\n",
    "    for ind in np.random.permutation(len(train_ids)):\n",
    "        # get the path from image id\n",
    "        train_id = train_ids[ind]\n",
    "        in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id)\n",
    "        in_path = in_files[np.random.random_integers(0, len(in_files) - 1)]\n",
    "        in_fn = os.path.basename(in_path)\n",
    "\n",
    "        gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id)\n",
    "        gt_path = gt_files[0]\n",
    "        gt_fn = os.path.basename(gt_path)\n",
    "        in_exposure = float(in_fn[9:-5])\n",
    "        gt_exposure = float(gt_fn[9:-5])\n",
    "        ratio = min(gt_exposure / in_exposure, 300)\n",
    "\n",
    "        st = time.time()\n",
    "        cnt += 1\n",
    "\n",
    "        if input_images[str(ratio)[0:3]][ind] is None:\n",
    "            #try:\n",
    "                raw = rawpy.imread(in_path)\n",
    "                input_images[str(ratio)[0:3]][ind] = np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
    "\n",
    "                gt_raw = rawpy.imread(gt_path)\n",
    "                im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "                gt_images[ind] = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "        # crop\n",
    "        H = input_images[str(ratio)[0:3]][ind].shape[1]\n",
    "        W = input_images[str(ratio)[0:3]][ind].shape[2]\n",
    "\n",
    "        xx = np.random.randint(0, W - ps)\n",
    "        yy = np.random.randint(0, H - ps)\n",
    "        input_patch = input_images[str(ratio)[0:3]][ind][:, yy:yy + ps, xx:xx + ps, :]\n",
    "        gt_patch = gt_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2, :]\n",
    "\n",
    "        if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
    "            input_patch = np.flip(input_patch, axis=1)\n",
    "            gt_patch = np.flip(gt_patch, axis=1)\n",
    "        if np.random.randint(2, size=1)[0] == 1:\n",
    "                    input_patch = np.flip(input_patch, axis=2)\n",
    "                    gt_patch = np.flip(gt_patch, axis=2)\n",
    "        if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
    "                    input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
    "                    gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\n",
    "\n",
    "        input_patch = np.minimum(input_patch, 1.0)\n",
    "\n",
    "        _, G_current, output = sess.run([G_opt, G_loss, out_image],\n",
    "                                                feed_dict={in_image: input_patch, gt_image: gt_patch, lr: learning_rate})\n",
    "        output = np.minimum(np.maximum(output, 0), 1)\n",
    "        g_loss[ind] = G_current\n",
    "        #print(g_loss[np.where(g_loss)])\n",
    "        print(\"%d , Count:  %d , Train ID: %d , Loss=%.3f , Time=%.3f\" % ((epoch+1), cnt,train_id, np.mean(g_loss[np.where(g_loss)]), time.time() - st))\n",
    "\n",
    "        if epoch % save_freq == 0:\n",
    "            if not os.path.isdir(result_dir + '%04d' % epoch):\n",
    "                os.makedirs(result_dir + '%04d' % epoch)\n",
    "\n",
    "            temp = np.concatenate((gt_patch[0, :, :, :], output[0, :, :, :]), axis=1)\n",
    "            Image.fromarray((temp * 255).astype(np.uint8),mode='RGB').save(\n",
    "                        result_dir + '%04d/%05d_00_train_%d.jpg' % (epoch, train_id, ratio))        \n",
    "        #except:\n",
    "        #    print(f\"Oops! {sys.exc_info()[0]} occurred for Train ID {train_id}, moving to next training ID....\")\n",
    "\n",
    "        #if cnt>=100:\n",
    "        #    break\n",
    "    print(f'------------------------------------------------------------------\\nEpoch: {epoch+1} to Epoch: {epoch+2}------------------------------------------------------------------\\n------------------------------------------------------------------')        \n",
    "    if not os.path.isdir(result_dir + 'model.ckpt'):\n",
    "      os.makedirs(result_dir + 'model.ckpt')\n",
    "    saver.save(sess, checkpoint_dir + 'model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c20a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "67d36878585a542570ff856abf0a24408e488838428cd0e62b2d6bf0a7575ba2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
